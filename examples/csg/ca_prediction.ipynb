{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from functools import partial\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import pathos.multiprocessing as mp\n",
    "from ssrs.raster import transform_coordinates, transform_bounds\n",
    "from ssrs.utils import get_extent_from_bounds\n",
    "from ssrs.movmodel import MovModel\n",
    "from dataclasses import replace, asdict\n",
    "from ssrs import Terrain, Simulator, Config, WTK\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "import scipy.spatial as spatial\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "clrs = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "        '#f781bf', '#a65628', '#984ea3',\n",
    "        '#999999', '#e41a1c', '#dede00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesfilt.telemetry.utils import *\n",
    "from bayesfilt.telemetry import Data3DEP, DataHRRR, Telemetry, TelemetryPlotter\n",
    "from simulate_tracks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 14s, sys: 5min 27s, total: 10min 42s\n",
      "Wall time: 10min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = get_annotated_telemetry_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12975662 entries, 0 to 12975661\n",
      "Data columns (total 118 columns):\n",
      " #    Column                 Dtype         \n",
      "---   ------                 -----         \n",
      " 0    AccelerationVer        float32       \n",
      " 1    AccelerationX          float32       \n",
      " 2    AccelerationX_var      float32       \n",
      " 3    AccelerationY          float32       \n",
      " 4    AccelerationY_var      float32       \n",
      " 5    AccelerationZ_var      float32       \n",
      " 6    AccnHorRadial          float32       \n",
      " 7    AccnHorTangential      float32       \n",
      " 8    Age                    category      \n",
      " 9    Altitude               float32       \n",
      " 10   AltitudeAgl            float32       \n",
      " 11   Altitude_var           float32       \n",
      " 12   AnimalID               int64         \n",
      " 13   BoundaryLayerHeight    float32       \n",
      " 14   FalseFix               bool          \n",
      " 15   GroundAspect           float32       \n",
      " 16   Elev                   float32       \n",
      " 17   GroundSlope            float32       \n",
      " 18   Group                  category      \n",
      " 19   Heading                float32       \n",
      " 20   HeadingRate            float64       \n",
      " 21   Latitude               float32       \n",
      " 22   Longitude              float32       \n",
      " 23   Oro                    float32       \n",
      " 24   OroSmooth              float32       \n",
      " 25   PositionX              float64       \n",
      " 26   PositionX_var          float32       \n",
      " 27   PositionY              float64       \n",
      " 28   PositionY_var          float32       \n",
      " 29   RadiusOfCurvature      float32       \n",
      " 30   Sex                    category      \n",
      " 31   Temperature0m          float32       \n",
      " 32   Temperature2m          float32       \n",
      " 33   TimeDiff               float32       \n",
      " 34   TimeLocal              datetime64[ns]\n",
      " 35   TimeUTC                datetime64[ns]\n",
      " 36   TrackID                int16         \n",
      " 37   TrackTimeElapsed       float32       \n",
      " 38   VelocityHor            float32       \n",
      " 39   VelocityVer            float32       \n",
      " 40   VelocityVer_var        float32       \n",
      " 41   VelocityX              float32       \n",
      " 42   VelocityX_var          float32       \n",
      " 43   VelocityY              float32       \n",
      " 44   VelocityY_var          float32       \n",
      " 45   WindDirection80m       float32       \n",
      " 46   WindLateral80m         float32       \n",
      " 47   WindRelativeAngle80m   float32       \n",
      " 48   WindSpeed80m           float32       \n",
      " 49   WindSpeedU80m          float32       \n",
      " 50   WindSpeedV80m          float32       \n",
      " 51   WindSupport80m         float32       \n",
      " 52   Agl                    float32       \n",
      " 53   HeadingRateRaw         float32       \n",
      " 54   HeadingRateAbs         float64       \n",
      " 55   WindLateral80mAbs      float32       \n",
      " 56   HrateByHspeed          float64       \n",
      " 57   VelocityHor_var        float32       \n",
      " 58   OroSmoothFifty         float32       \n",
      " 59   OroSmoothFiftyDiff     float32       \n",
      " 60   OroSmoothFiftyL15Diff  float32       \n",
      " 61   OroSmoothFiftyR15Diff  float32       \n",
      " 62   OroSmoothFiftyL30Diff  float32       \n",
      " 63   OroSmoothFiftyR30Diff  float32       \n",
      " 64   OroSmoothFiftyL60Diff  float32       \n",
      " 65   OroSmoothFiftyR60Diff  float32       \n",
      " 66   ElevFifty              float32       \n",
      " 67   ElevFiftyDiff          float32       \n",
      " 68   ElevFiftyL15Diff       float32       \n",
      " 69   ElevFiftyR15Diff       float32       \n",
      " 70   ElevFiftyL30Diff       float32       \n",
      " 71   ElevFiftyR30Diff       float32       \n",
      " 72   ElevFiftyL60Diff       float32       \n",
      " 73   ElevFiftyR60Diff       float32       \n",
      " 74   OroSmoothOnehd         float32       \n",
      " 75   OroSmoothOnehdDiff     float32       \n",
      " 76   OroSmoothOnehdL15Diff  float32       \n",
      " 77   OroSmoothOnehdR15Diff  float32       \n",
      " 78   OroSmoothOnehdL30Diff  float32       \n",
      " 79   OroSmoothOnehdR30Diff  float32       \n",
      " 80   OroSmoothOnehdL60Diff  float32       \n",
      " 81   OroSmoothOnehdR60Diff  float32       \n",
      " 82   ElevOnehd              float32       \n",
      " 83   ElevOnehdDiff          float32       \n",
      " 84   ElevOnehdL15Diff       float32       \n",
      " 85   ElevOnehdR15Diff       float32       \n",
      " 86   ElevOnehdL30Diff       float32       \n",
      " 87   ElevOnehdR30Diff       float32       \n",
      " 88   ElevOnehdL60Diff       float32       \n",
      " 89   ElevOnehdR60Diff       float32       \n",
      " 90   OroSmoothTwohd         float32       \n",
      " 91   OroSmoothTwohdDiff     float32       \n",
      " 92   OroSmoothTwohdL15Diff  float32       \n",
      " 93   OroSmoothTwohdR15Diff  float32       \n",
      " 94   OroSmoothTwohdL30Diff  float32       \n",
      " 95   OroSmoothTwohdR30Diff  float32       \n",
      " 96   OroSmoothTwohdL60Diff  float32       \n",
      " 97   OroSmoothTwohdR60Diff  float32       \n",
      " 98   ElevTwohd              float32       \n",
      " 99   ElevTwohdDiff          float32       \n",
      " 100  ElevTwohdL15Diff       float32       \n",
      " 101  ElevTwohdR15Diff       float32       \n",
      " 102  ElevTwohdL30Diff       float32       \n",
      " 103  ElevTwohdR30Diff       float32       \n",
      " 104  ElevTwohdL60Diff       float32       \n",
      " 105  ElevTwohdR60Diff       float32       \n",
      " 106  OroSmoothFvehd         float32       \n",
      " 107  OroSmoothFvehdDiff     float32       \n",
      " 108  ElevFvehd              float32       \n",
      " 109  ElevFvehdDiff          float32       \n",
      " 110  OroSmoothOnekm         float32       \n",
      " 111  OroSmoothOnekmDiff     float32       \n",
      " 112  ElevOnekm              float32       \n",
      " 113  ElevOnekmDiff          float32       \n",
      " 114  OroSmoothTwokm         float32       \n",
      " 115  OroSmoothTwokmDiff     float32       \n",
      " 116  ElevTwokm              float32       \n",
      " 117  ElevTwokmDiff          float32       \n",
      "dtypes: bool(1), category(3), datetime64[ns](2), float32(105), float64(5), int16(1), int64(1)\n",
      "memory usage: 5.9 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = 'fit_ca.pickle_robust'\n",
    "with open(os.path.join(OUT_DIR,f'{model_str}_model'), 'rb') as outp:\n",
    "    models = pickle.load(outp)\n",
    "with open(os.path.join(OUT_DIR,f'{model_str}_funcs'), 'rb') as outp:\n",
    "    std_funcs = pickle.load(outp)\n",
    "with open(os.path.join(OUT_DIR,f'{model_str}_df'), 'rb') as outp:\n",
    "    dfshort = pickle.load(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f'{model_str}_simulation_r75' works\n",
    "case_str = f'{model_str}_simulation_r75'\n",
    "#case_str = f'{model_str}_simulation_5min_r75_100'\n",
    "with open(os.path.join(OUT_DIR, case_str), \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "def get_xy_data(idf, xname, yname):\n",
    "    quant = 0.95\n",
    "    xgrid = np.linspace(*np.quantile(idf[xname], [1 - quant, quant]), 50)\n",
    "    rdfshortb = pd.DataFrame({'x': idf[xname], 'y': idf[yname]})\n",
    "    rdfshortb['bin_col'] = np.searchsorted(xgrid, idf[xname])\n",
    "    bin_groups = rdfshortb.groupby(by='bin_col')\n",
    "    ydata = bin_groups['y'].median()[:-1]\n",
    "    yerr = bin_groups['y'].std()[:-1]\n",
    "    ydata = ydata.rolling(3, min_periods=1, center=True).mean().bfill().ffill()\n",
    "    return xgrid, ydata, yerr\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrack = 104#22, 23, 130, 152, 156, 176\n",
    "colnames = [\n",
    "    'Altitude', 'Agl', 'VelocityVer', 'VelocityHor', 'HeadingRate', 'Heading',\n",
    "    'WindLateral80m', 'WindSupport80m', 'WindRelativeAngle80m',#'ElevNearDiff'\n",
    "    'WindDirection80m', 'WindSpeed80m', \n",
    "]\n",
    "fig, ax = plot_sim_tracks_in_space2(results[itrack], max_agl=200., time_pad=[150,180], zoom=1700, savefig=False)\n",
    "fig, ax = plot_sim_tracks_in_time(results[itrack], colnames=colnames)\n",
    "# for iax in ax:\n",
    "#     iax.set_xlim([0,60])\n",
    "# find tracks in 2d, agl, topograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "list_of_tlocs = [30, 60, 90, 120,150,180]\n",
    "for err_at in list_of_tlocs:\n",
    "    hpos_err = []\n",
    "    for ituple in results:\n",
    "        ix, idf, ids, ilist_of_df = ituple\n",
    "        xdiff = idf['PositionX'].iloc[1] - idf['PositionX'].iloc[0]\n",
    "        ydiff = idf['PositionY'].iloc[1] - idf['PositionY'].iloc[0]\n",
    "        heading = np.arctan2(xdiff, ydiff)\n",
    "        for jdf in ilist_of_df:\n",
    "            heading = np.radians(jdf['Heading'].iloc[0])\n",
    "            hspeed = idf['VelocityHor'].iloc[0]\n",
    "            vspeed = idf['VelocityVer'].iloc[0]\n",
    "            xloc = jdf['PositionX'].iloc[0] + np.sin(heading)*hspeed*err_at\n",
    "            yloc = jdf['PositionY'].iloc[0] + np.cos(heading)*hspeed*err_at\n",
    "            zloc = jdf['Altitude'].iloc[0] + vspeed*err_at\n",
    "            xerr = xloc-idf['PositionX'].iloc[err_at]\n",
    "            yerr = yloc-idf['PositionY'].iloc[err_at]\n",
    "            zerr = zloc-idf['Altitude'].iloc[err_at]\n",
    "            hpos_err.append({'xres':xerr, 'yres':yerr,'zres':zerr})\n",
    "    edf = pd.DataFrame(hpos_err)\n",
    "    edf['rdist'] = np.sqrt(1*edf['xres']**2 + 1*edf['yres']**2 + 1*edf['zres']**2)\n",
    "    list_of_dfs.append(edf)\n",
    "rdist_adhoc = [idf['rdist'] for idf in list_of_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "for err_at in list_of_tlocs:\n",
    "    hpos_err = []\n",
    "    for ituple in results:\n",
    "        ix, idf, ids, ilist_of_df = ituple\n",
    "        jbool = (idf['OroSmooth'].quantile(0.5) > 0.0)\n",
    "        #jbool = (idf['VelocityVer'].quantile(0.5) > 0.0)\n",
    "        #jbool = jbool & (idf['Agl'].quantile(0.75)<200)\n",
    "        #jbool = jbool & (idf['VelocityHor'].quantile(0.75)>2.)\n",
    "        #jbool = jbool & (ids.WindSpeed80m.median().item() > 5.)\n",
    "        if jbool:\n",
    "            for jdf in ilist_of_df:\n",
    "                jbool = (jdf.shape[0] > err_at) & (jdf['OroSmooth'].quantile(0.5) > 0.0)\n",
    "                if jbool:\n",
    "                    #print(jdf['TrackTimeElapsed'].iloc[err_at], idf['TrackTimeElapsed'].iloc[err_at])\n",
    "                    ibool = (jdf['Agl'].iloc[err_at] <1300) & (jdf['OroSmooth'].iloc[err_at] >= 0.0)\n",
    "                    ibool = ibool & (jdf['VelocityVer'].iloc[err_at] > -100.)\n",
    "                    if ibool:\n",
    "                        xerr = jdf['PositionX'].iloc[err_at]-idf['PositionX'].iloc[err_at]\n",
    "                        yerr = jdf['PositionY'].iloc[err_at]-idf['PositionY'].iloc[err_at]\n",
    "                        zerr = jdf['Altitude'].iloc[err_at]-idf['Altitude'].iloc[err_at]\n",
    "                        hpos_err.append({'xres':xerr, 'yres':yerr,'zres':zerr})\n",
    "    edf = pd.DataFrame(hpos_err)\n",
    "    edf['rdist'] = np.sqrt(1*edf['xres']**2 + 1*edf['yres']**2 + 1*edf['zres']**2)\n",
    "    list_of_dfs.append(edf)\n",
    "rdist_model = [idf['rdist'] for idf in list_of_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "for err_at in list_of_tlocs:\n",
    "    hpos_err = []\n",
    "    for ituple in results:\n",
    "        ix, idf, ids, ilist_of_df = ituple\n",
    "        jbool = (idf['OroSmooth'].quantile(0.5) > 0.0)\n",
    "        #jbool = (idf['VelocityVer'].quantile(0.5) > 0.0)\n",
    "        #jbool = jbool & (idf['Agl'].quantile(0.75)<150)\n",
    "        #jbool = jbool & (idf['VelocityHor'].quantile(0.75)>2.)\n",
    "        jbool = jbool & (ids.WindSpeed80m.median().item() > 15.)\n",
    "        if jbool:\n",
    "            for jdf in ilist_of_df:\n",
    "                jbool = (jdf.shape[0] > err_at) & (jdf['OroSmooth'].quantile(0.5) > 0.0)\n",
    "                if jbool:\n",
    "                    #print(jdf['TrackTimeElapsed'].iloc[err_at], idf['TrackTimeElapsed'].iloc[err_at])\n",
    "                    ibool = (jdf['Agl'].iloc[err_at] <1500) & (jdf['OroSmooth'].iloc[err_at] > 0.0)\n",
    "                    ibool = ibool & (jdf['VelocityVer'].iloc[err_at] > -100.)\n",
    "                    if ibool:\n",
    "                        xerr = jdf['PositionX'].iloc[err_at]-idf['PositionX'].iloc[err_at]\n",
    "                        yerr = jdf['PositionY'].iloc[err_at]-idf['PositionY'].iloc[err_at]\n",
    "                        zerr = jdf['Altitude'].iloc[err_at]-idf['Altitude'].iloc[err_at]\n",
    "                        hpos_err.append({'xres':xerr, 'yres':yerr,'zres':zerr})\n",
    "    edf = pd.DataFrame(hpos_err)\n",
    "    edf['rdist'] = np.sqrt(1*edf['xres']**2 + 1*edf['yres']**2 + 1*edf['zres']**2)\n",
    "    list_of_dfs.append(edf)\n",
    "rdist_model_windy = [idf['rdist'] for idf in list_of_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "for err_at in list_of_tlocs:\n",
    "    hpos_err = []\n",
    "    for ituple in results:\n",
    "        ix, idf, ids, ilist_of_df = ituple\n",
    "        jbool = (idf['OroSmooth'].quantile(0.5) > 0.0)\n",
    "        #jbool = (idf['VelocityVer'].quantile(0.5) > 0.0)\n",
    "        jbool = jbool & (idf['Agl'].quantile(0.75)<130)\n",
    "        #jbool = jbool & (idf['VelocityHor'].quantile(0.75)>2.)\n",
    "        jbool = jbool & (ids.WindSpeed80m.median().item() > 15.)\n",
    "        if jbool:\n",
    "            for jdf in ilist_of_df:\n",
    "                jbool = (jdf.shape[0] > err_at) & (jdf['OroSmooth'].quantile(0.5) > 0.0)\n",
    "                if jbool:\n",
    "                    #print(jdf['TrackTimeElapsed'].iloc[err_at], idf['TrackTimeElapsed'].iloc[err_at])\n",
    "                    ibool = (jdf['Agl'].iloc[err_at] <130) & (jdf['OroSmooth'].iloc[err_at] > 0.0)\n",
    "                    ibool = ibool & (jdf['VelocityVer'].iloc[err_at] > -100.)\n",
    "                    if ibool:\n",
    "                        xerr = jdf['PositionX'].iloc[err_at]-idf['PositionX'].iloc[err_at]\n",
    "                        yerr = jdf['PositionY'].iloc[err_at]-idf['PositionY'].iloc[err_at]\n",
    "                        zerr = jdf['Altitude'].iloc[err_at]-idf['Altitude'].iloc[err_at]\n",
    "                        hpos_err.append({'xres':xerr, 'yres':yerr,'zres':zerr})\n",
    "    edf = pd.DataFrame(hpos_err)\n",
    "    edf['rdist'] = np.sqrt(1*edf['xres']**2 + 1*edf['yres']**2 + 1*edf['zres']**2)\n",
    "    list_of_dfs.append(edf)\n",
    "rdist_model_windy_rsz = [idf['rdist'] for idf in list_of_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "for err_at in list_of_tlocs:\n",
    "    hpos_err = []\n",
    "    for ituple in results:\n",
    "        ix, idf, ids, ilist_of_df = ituple\n",
    "        jbool = (idf['OroSmooth'].quantile(0.5) > 0.75)\n",
    "        #jbool = (idf['VelocityVer'].quantile(0.5) > 0.0)\n",
    "        jbool = jbool & (idf['Agl'].quantile(0.75)<130)\n",
    "        #jbool = jbool & (idf['VelocityHor'].quantile(0.75)>2.)\n",
    "        jbool = jbool & (ids.WindSpeed80m.median().item() > 15.)\n",
    "        if jbool:\n",
    "            for jdf in ilist_of_df:\n",
    "                jbool = (jdf.shape[0] > err_at) & (jdf['VelocityVer'].quantile(0.5) > 0.0)\n",
    "                if jbool:\n",
    "                    #print(jdf['TrackTimeElapsed'].iloc[err_at], idf['TrackTimeElapsed'].iloc[err_at])\n",
    "                    ibool = (jdf['Agl'].iloc[err_at] <130) & (jdf['OroSmooth'].iloc[err_at] > 0.75)\n",
    "                    ibool = ibool & (jdf['VelocityVer'].iloc[err_at] > 0.)\n",
    "                    if ibool:\n",
    "                        xerr = jdf['PositionX'].iloc[err_at]-idf['PositionX'].iloc[err_at]\n",
    "                        yerr = jdf['PositionY'].iloc[err_at]-idf['PositionY'].iloc[err_at]\n",
    "                        zerr = jdf['Altitude'].iloc[err_at]-idf['Altitude'].iloc[err_at]\n",
    "                        hpos_err.append({'xres':xerr, 'yres':yerr,'zres':zerr})\n",
    "    edf = pd.DataFrame(hpos_err)\n",
    "    edf['rdist'] = np.sqrt(1*edf['xres']**2 + 1*edf['yres']**2 + 1*edf['zres']**2)\n",
    "    list_of_dfs.append(edf)\n",
    "rdist_model_windy_rsz_soaring = [idf['rdist'] for idf in list_of_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,3))\n",
    "xlbls = [f'{ix}' for ix in list_of_tlocs]\n",
    "dict_of_data = {\n",
    "    'Model (Windy+RSZ+Soaring)': rdist_model_windy_rsz_soaring, \n",
    "    'Model (Windy+RSZ)': rdist_model_windy_rsz,\n",
    "    'Model (Windy)': rdist_model_windy, \n",
    "    'Model': rdist_model, \n",
    "    'CV': rdist_adhoc\n",
    "}\n",
    "list_of_pos_shift = [-0.3, -0.15, 0., 0.15, 0.3]\n",
    "list_of_pos = [np.arange(len(list_of_tlocs)) for _ in range(len(dict_of_data))]\n",
    "list_of_pos = [ix+iy for ix,iy in zip(list_of_pos, list_of_pos_shift)]\n",
    "list_of_patches = []\n",
    "ax2 = ax.twinx()\n",
    "for i, (ilbl, idata) in enumerate(dict_of_data.items()):\n",
    "    bp = ax.boxplot(\n",
    "        idata,  \n",
    "        sym='', \n",
    "        whis=1., \n",
    "        positions = list_of_pos[i], \n",
    "        widths=0.1, \n",
    "        meanline=True,\n",
    "        patch_artist=True, \n",
    "        manage_ticks=False\n",
    "    )\n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[element], color=clrs[i])\n",
    "    list_of_patches.append(mpatches.Patch(color=clrs[i], label=ilbl))\n",
    "#ax.grid(True)\n",
    "ax.set_xticks(np.arange(len(list_of_tlocs)))\n",
    "ax.set_xticklabels(xlbls)\n",
    "ax.legend(handles=list_of_patches, loc=2, borderaxespad=0.)\n",
    "ax.set_ylim([0,130*25])\n",
    "ax2.set_ylim([0,25])\n",
    "ax.set_xlabel('Time elapsed since start [s]')\n",
    "ax.set_ylabel('Radial distance [m]')\n",
    "ax2.set_ylabel('# of rotor diameters')\n",
    "#fig.savefig(os.path.join(FIG_DIR,f'fig_validation_{case_str}_radial.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfshort.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "xnames = [\n",
    "    #'OroSmoothFiftyDiff', 'OroSmoothOnehdDiff', 'OroSmoothTwohdDiff', 'OroSmoothFvehdDiff', 'OroSmoothOnekmDiff',\n",
    "    'OroSmoothFiftyDiffStd', 'OroSmoothOnehdDiffStd', 'OroSmoothTwohdDiffStd', 'OroSmoothFvehdDiffStd', 'OroSmoothOnekmDiffStd',\n",
    "]\n",
    "lstyles = ['-','--','-.',':', '-']\n",
    "lbls = ['50 m', '100m', '250 m','500 m','1 km','2 km']\n",
    "# name it in \n",
    "yname = 'VelocityVerNext'\n",
    "#yname = 'AccnHorTangential'\n",
    "#idf = dfshort[dfshort['OroSmoothFartherDiff']>dfshort['OroSmoothCloseDiff']]\n",
    "idf = dfshort\n",
    "quant = 0.95\n",
    "# max of all oro's vs \n",
    "for i, xname in enumerate(xnames):\n",
    "    xgrid = np.linspace(*np.quantile(idf[xname], [1 - quant, quant]), 50)\n",
    "    rdfshortb = pd.DataFrame({'x': idf[xname], 'y': idf[yname]})\n",
    "    rdfshortb['bin_col'] = np.searchsorted(xgrid, idf[xname])\n",
    "    bin_groups = rdfshortb.groupby(by='bin_col')\n",
    "    ydata = bin_groups['y'].mean()[:-1]\n",
    "    yerr = bin_groups['y'].std()[:-1]\n",
    "    ydata = ydata.rolling(7, min_periods=1, center=True).mean().bfill().ffill()\n",
    "    ydata -= dfshort[yname].mean()\n",
    "    ax.plot(xgrid, ydata, linestyle=lstyles[i], color=clrs[i], linewidth=2., alpha=0.75, label=lbls[i])\n",
    "    #ax.plot(xgrid, ydata-yerr, linestyle='--', color=clrs[i], linewidth=2., alpha=0.75, label=lbls[i])\n",
    "    #ax.plot(xgrid, ydata+yerr, linestyle='--', color=clrs[i], linewidth=2., alpha=0.75, label=lbls[i])\n",
    "ax.legend(borderaxespad=0.)\n",
    "ax.set_xlabel('Difference in orographic updraft from PF [m/s]')\n",
    "ax.set_ylabel(r'$\\Delta v_h$ around median [m/s]')\n",
    "ax.grid(True)\n",
    "#ax.set_xlim([0,1])\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(FIG_DIR,f'{yname}_oro.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfshort.VelocityHor.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfshort.groupby('Group')['TrackID'].count()*100/dfshort.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5.5,3))\n",
    "xnames = ['OroSmoothNearL30Diff', 'OroSmoothNearR30Diff', \n",
    "          'OroSmoothCloseL30Diff', 'OroSmoothCloseR30Diff',\n",
    "          #'OroSmoothNearL60Diff', 'OroSmoothNearR60Diff', \n",
    "          #'OroSmoothCloseL60Diff', 'OroSmoothCloseR60Diff',\n",
    "          ]\n",
    "lbls = ['F50L30','F50R30','F250L30','F250R30','F50L60','F50R60','F250L60','F250R60']\n",
    "lbls = [r'50 m, -30$^o$', r'50 m, 30$^o$', r'250 m, -30$^o$',r'250 m, 30$^o$', \n",
    "        r'50 m, -60$^o$',r'50 m, 60$^o$', r'250 m, -60$^o$',r'250 m, 60$^o$']\n",
    "#iclrs = [clrs[0], clrs[0]]\n",
    "# F250\n",
    "# color schemes for the two figures\n",
    "yname = 'HeadingRateNext'\n",
    "idf = dfshort\n",
    "quant = 0.9\n",
    "for i, xname in enumerate(xnames):\n",
    "    xgrid = np.linspace(*np.quantile(idf[xname].abs(), [1 - quant, quant]), 50)\n",
    "    rdfshortb = pd.DataFrame({'x': idf[xname].abs(), 'y': idf[yname]})\n",
    "    rdfshortb['bin_col'] = np.searchsorted(xgrid, idf[xname])\n",
    "    bin_groups = rdfshortb.groupby(by='bin_col')\n",
    "    ydata = bin_groups['y'].mean()[:-1]\n",
    "    yerr = bin_groups['y'].std()[:-1]\n",
    "    ydata = ydata.rolling(7, min_periods=1, center=True).mean().bfill().ffill()\n",
    "    ax.plot(xgrid, ydata, linestyle='-', color=clrs[i], linewidth=2., alpha=0.75, label=lbls[i])\n",
    "ax.legend(borderaxespad=0., ncol=2)\n",
    "ax.set_xlabel('Difference in orographic updraft from NF/CF [m/s]')\n",
    "ax.set_ylabel('Heading rate, median [deg/s]')\n",
    "ax.grid(True)\n",
    "ax.set_xlim([-0.0,0.1])\n",
    "ax.set_ylim([-0.4,0.4])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(FIG_DIR,f'{yname}_oro.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfshort['OroSmoothNearLeftMaxDiff'] = np.maximum.reduce([\n",
    "    dfshort['OroSmoothNearL15Diff'],\n",
    "    dfshort['OroSmoothNearL30Diff'],\n",
    "    dfshort['OroSmoothNearL60Diff']\n",
    "])\n",
    "dfshort['OroSmoothNearRightMaxDiff'] = np.maximum.reduce([\n",
    "    dfshort['OroSmoothNearR15Diff'],\n",
    "    dfshort['OroSmoothNearR30Diff'],\n",
    "    dfshort['OroSmoothNearR60Diff']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5.5,3))\n",
    "case_dict = {\n",
    "#     'OroSmoothNearLeftMaxDiff':'left max',\n",
    "#      'OroSmoothNearRightMaxDiff':'right max',\n",
    "    'OroSmoothNearL15Diff': r'50 m, -15$^o$', \n",
    "    'OroSmoothNearR15Diff': r'50 m, 15$^o$', \n",
    "    'OroSmoothNearL30Diff': r'50 m, -30$^o$', \n",
    "    'OroSmoothNearR30Diff': r'50 m, 30$^o$',\n",
    "    'OroSmoothNearL60Diff': r'50 m, -60$^o$', \n",
    "    'OroSmoothNearR60Diff': r'50 m, 60$^o$',\n",
    "}\n",
    "# F250\n",
    "# color schemes for the two figures\n",
    "yname = 'HeadingRateNext'\n",
    "idf = dfshort\n",
    "quant = 0.9\n",
    "for i, (xname, lbl) in enumerate(case_dict.items()):\n",
    "    xgrid = np.linspace(*np.quantile(idf[xname], [1 - quant, quant]), 50)\n",
    "    rdfshortb = pd.DataFrame({'x': idf[xname], 'y': idf[yname]})\n",
    "    rdfshortb['bin_col'] = np.searchsorted(xgrid, idf[xname])\n",
    "    bin_groups = rdfshortb.groupby(by='bin_col')\n",
    "    ydata = bin_groups['y'].mean()[:-1]\n",
    "    yerr = bin_groups['y'].std()[:-1]\n",
    "    ydata = ydata.rolling(9, min_periods=1, center=True).mean().bfill().ffill()\n",
    "    ax.plot(xgrid, ydata, linestyle='-', color=clrs[i], linewidth=2., alpha=0.75, label=lbl)\n",
    "ax.legend(borderaxespad=0., ncol=3)\n",
    "ax.set_xlabel('Difference in orographic updraft from NF/CF [m/s]')\n",
    "ax.set_ylabel('Heading rate, median [deg/s]')\n",
    "ax.grid(True)\n",
    "ax.set_xlim([-0.3,0.3])\n",
    "ax.set_ylim([-0.5,0.5])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(FIG_DIR,f'{yname}_oro2.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5.5,3))\n",
    "case_dict = {\n",
    "#     'OroSmoothNearLeftMaxDiff':'left max',\n",
    "#      'OroSmoothNearRightMaxDiff':'right max',\n",
    "    'OroSmoothCloseL15Diff': r'50 m, -15$^o$', \n",
    "    'OroSmoothCloseR15Diff': r'50 m, 15$^o$', \n",
    "    'OroSmoothCloseL30Diff': r'50 m, -30$^o$', \n",
    "    'OroSmoothCloseR30Diff': r'50 m, 30$^o$',\n",
    "    'OroSmoothCloseL60Diff': r'50 m, -60$^o$', \n",
    "    'OroSmoothCloseR60Diff': r'50 m, 60$^o$',\n",
    "}\n",
    "# F250\n",
    "# color schemes for the two figures\n",
    "yname = 'HeadingRateNext'\n",
    "idf = dfshort\n",
    "quant = 0.9\n",
    "for i, (xname, lbl) in enumerate(case_dict.items()):\n",
    "    xgrid = np.linspace(*np.quantile(idf[xname], [1 - quant, quant]), 50)\n",
    "    rdfshortb = pd.DataFrame({'x': idf[xname], 'y': idf[yname]})\n",
    "    rdfshortb['bin_col'] = np.searchsorted(xgrid, idf[xname])\n",
    "    bin_groups = rdfshortb.groupby(by='bin_col')\n",
    "    ydata = bin_groups['y'].mean()[:-1]\n",
    "    yerr = bin_groups['y'].std()[:-1]\n",
    "    ydata = ydata.rolling(9, min_periods=1, center=True).mean().bfill().ffill()\n",
    "    ax.plot(xgrid, ydata, linestyle='-', color=clrs[i], linewidth=2., alpha=0.75, label=lbl)\n",
    "ax.legend(borderaxespad=0., ncol=3)\n",
    "ax.set_xlabel('Difference in orographic updraft from NF/CF [m/s]')\n",
    "ax.set_ylabel('Heading rate, median [deg/s]')\n",
    "ax.grid(True)\n",
    "ax.set_xlim([-0.3,0.3])\n",
    "ax.set_ylim([-0.5,0.5])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(FIG_DIR,f'{yname}_oro2.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5.5,3))\n",
    "xnames = ['OroSmoothNearL30Diff', 'OroSmoothNearR30Diff', \n",
    "          #'OroSmoothCloseL30Diff', 'OroSmoothCloseR30Diff',\n",
    "          'OroSmoothNearL60Diff', 'OroSmoothNearR60Diff', \n",
    "          #'OroSmoothCloseL60Diff', 'OroSmoothCloseR60Diff',\n",
    "          ]\n",
    "lbls = ['F50L30','F50R30','F250L30','F250R30','F50L60','F50R60','F250L60','F250R60']\n",
    "lbls = [r'250 m, -30$^o$',r'250 m, 30$^o$',r'250 m, -60$^o$',r'250 m, 60$^o$']\n",
    "#iclrs = [clrs[0], clrs[0]]\n",
    "# F250\n",
    "# color schemes for the two figures\n",
    "yname = 'HeadingRateNext'\n",
    "idf = dfshort\n",
    "quant = 0.9\n",
    "for i, xname in enumerate(xnames):\n",
    "    xgrid = np.linspace(*np.quantile(idf[xname], [1 - quant, quant]), 50)\n",
    "    rdfshortb = pd.DataFrame({'x': idf[xname], 'y': idf[yname]})\n",
    "    rdfshortb['bin_col'] = np.searchsorted(xgrid, idf[xname])\n",
    "    bin_groups = rdfshortb.groupby(by='bin_col')\n",
    "    ydata = bin_groups['y'].mean()[:-1]\n",
    "    yerr = bin_groups['y'].std()[:-1]\n",
    "    ydata = ydata.rolling(7, min_periods=1, center=True).mean().bfill().ffill()\n",
    "    ax.plot(xgrid, ydata, linestyle='-', color=clrs[i], linewidth=2., alpha=0.75, label=lbls[i])\n",
    "ax.legend(borderaxespad=0., ncol=2)\n",
    "ax.set_xlabel('Difference in orographic updraft from NF/CF [m/s]')\n",
    "ax.set_ylabel('Heading rate, median [deg/s]')\n",
    "ax.grid(True)\n",
    "ax.set_xlim([-0.1,0.1])\n",
    "ax.set_ylim([-0.4,0.4])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(FIG_DIR,f'{yname}_oro2.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.5,3))\n",
    "idf = dfshort[dfshort['WindSpeed80m']<100.]\n",
    "xdata, ydata, ystd = get_xy_data(idf, 'WindSupport80m','VelocityHorNext')\n",
    "ax.plot(xdata, ydata, '-r', color=clrs[0],linewidth=2., alpha=0.75, label='Tailwind')\n",
    "xdata, ydata, ystd = get_xy_data(idf, 'WindLateral80m','VelocityHorNext')\n",
    "ax.plot(xdata, ydata, '-b', color=clrs[1], linewidth=2., alpha=0.75, label='Crosswind')\n",
    "# xdata, ydata, ystd = get_xy_data(dfshort, 'WindSpeed80m','VelocityVerNext')\n",
    "# ax.plot(xdata, ydata, '-b', linewidth=2., alpha=0.75)\n",
    "ax.legend(borderaxespad=0.)\n",
    "ax.set_xlabel('Wind speed [m/s]')\n",
    "ax.set_ylabel(r'Horizontal speed, median [m/s]')\n",
    "ax.grid(True)\n",
    "# ax.set_xlim([-5,5])\n",
    "# ax.set_ylim([-0.5,0.5])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(FIG_DIR,'fig_wind_velocityhor.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.5,3))\n",
    "idf = dfshort[dfshort['WindSpeed80m']<100.]\n",
    "xdata, ydata, ystd = get_xy_data(idf, 'WindSupport80m','VelocityVerNext')\n",
    "ax.plot(xdata, ydata, '-r', color=clrs[0],linewidth=2., alpha=0.75, label='Tailwind')\n",
    "xdata, ydata, ystd = get_xy_data(idf, 'WindLateral80m','VelocityVerNext')\n",
    "ax.plot(xdata, ydata, '-b', color=clrs[1], linewidth=2., alpha=0.75, label='Crosswind')\n",
    "xdata, ydata, ystd = get_xy_data(dfshort, 'WindSpeed80m','VelocityVerNext')\n",
    "#ax.plot(xdata, ydata, '-b', linewidth=2., alpha=0.75, label='Wind')\n",
    "ax.legend(borderaxespad=0.)\n",
    "ax.set_xlabel('Wind speed [m/s]')\n",
    "ax.set_ylabel('Vertical speed, median [m/s]')\n",
    "ax.grid(True)\n",
    "# ax.set_xlim([-5,5])\n",
    "# ax.set_ylim([-0.5,0.5])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(FIG_DIR,'fig_wind_velocityver.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfshort.WindSpeed80m.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "xnames = ['OroSmoothNearDiff', 'OroSmoothCloseDiff', 'OroSmoothMidDiff', \n",
    "          'OroSmoothFarDiff']\n",
    "clrs = ['b','r','g','c','k']\n",
    "lbls = ['NF-PF','CF-PF','MF-PF','FF-PF','ddd']\n",
    "yname = 'VelocityVerNext'\n",
    "idf = dfshort\n",
    "quant = 0.9999\n",
    "for i, xname in enumerate(xnames):\n",
    "    xgrid = np.linspace(*np.quantile(idf[xname], [1 - quant, quant]), 50)\n",
    "    rdfshortb = pd.DataFrame({'x': idf[xname], 'y': idf[yname]})\n",
    "    rdfshortb['bin_col'] = np.searchsorted(xgrid, idf[xname])\n",
    "    bin_groups = rdfshortb.groupby(by='bin_col')\n",
    "    ydata = bin_groups['y'].median()[:-1]\n",
    "    yerr = bin_groups['y'].std()[:-1]\n",
    "    ydata = ydata.rolling(7, min_periods=1, center=True).mean().bfill().ffill()\n",
    "    ax.plot(xgrid, ydata, linestyle='-', color=clrs[i], linewidth=2., alpha=0.75, label=lbls[i])\n",
    "ax.legend(borderaxespad=0.)\n",
    "ax.set_xlabel('Variation in orographic updraft [m/s]')\n",
    "ax.set_ylabel('Vertical speed [m/s]')\n",
    "ax.grid(True)\n",
    "ax.set_xlim([-2,2])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(FIG_DIR,f'{yname}_oro.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "xnames = ['ElevNearDiff', 'ElevCloseDiff', 'ElevMidDiff', 'ElevFarDiff']\n",
    "clrs = ['b','r','g','c','k']\n",
    "lbls = ['NF-PF','CF-PF','MF-PF','FF-PF','ddd']\n",
    "yname = 'HeadingRateNext'\n",
    "idf = dfshort\n",
    "quant = 0.9999\n",
    "for i, xname in enumerate(xnames):\n",
    "    xgrid = np.linspace(*np.quantile(idf[xname], [1 - quant, quant]), 50)\n",
    "    rdfshortb = pd.DataFrame({'x': idf[xname], 'y': idf[yname]})\n",
    "    rdfshortb['bin_col'] = np.searchsorted(xgrid, idf[xname])\n",
    "    bin_groups = rdfshortb.groupby(by='bin_col')\n",
    "    ydata = bin_groups['y'].mean()[:-1]\n",
    "    yerr = bin_groups['y'].std()[:-1]\n",
    "    ydata = ydata.rolling(3, min_periods=1, center=True).mean().bfill().ffill()\n",
    "    #ydata -= idf['HeadingRate'].mean()\n",
    "    ax.plot(xgrid, ydata, linestyle='-', color=clrs[i], linewidth=2., alpha=0.75, label=lbls[i])\n",
    "ax.legend(borderaxespad=0.)\n",
    "ax.set_xlabel('Variation in ground elevation [std]')\n",
    "ax.set_ylabel('Vertical speed [std]')\n",
    "ax.grid(True)\n",
    "ax.set_xlim([-3,3])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(FIG_DIR,f'{yname}_elev.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    idx, idf, ids, list_of_simdf  = sim_results[itrack]\n",
    "    print('here')\n",
    "except:\n",
    "     idx, idf, ids  = sim_results[itrack]\n",
    "lag_colnames = [ix.split('Next')[0] for ix in models.columns]\n",
    "list_of_start_states = gather_starting_locs(\n",
    "    [idx, idf, ids], \n",
    "    lag_cols=lag_colnames, \n",
    "    ntracks=10, \n",
    "    dict_of_scales={\n",
    "            'PositionX': 10,\n",
    "            'PositionY': 10,\n",
    "            'Altitude': 2.,\n",
    "            'VelocityHor': 1.,\n",
    "            'VelocityVer': 1.,\n",
    "            'HeadingRate': 0.1,\n",
    "            'HrateByHspeed': 0.5,\n",
    "            'Heading': 5.\n",
    "        }\n",
    ")\n",
    "simdf = generate_track(\n",
    "    start_state = list_of_start_states[0],\n",
    "    ids=ids,\n",
    "    models=models,\n",
    "    std_funcs=std_funcs,\n",
    "    num_steps=int(idf['TrackTimeElapsed'].iloc[-1]),\n",
    "    mtype='LinReg',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoints = sdf[['PositionX','PositionY','Agl']].astype(int)\n",
    "# spoints = \n",
    "# tree = spatial.KDTree(spoints)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnge = [[ids.x.min(), ids.x.max()],[ids.y.min(), ids.y.max()]]\n",
    "sdf = pd.concat(list_of_simdf)\n",
    "sdf = sdf[sdf['TrackTimeElapsed'] > 0]\n",
    "H,xedges,yedges= np.histogram2d(sdf['PositionX'], sdf['PositionY'], bins=100, range=rnge)\n",
    "gf_func = partial(\n",
    "    gaussian_filter,\n",
    "    sigma=1,\n",
    "    mode='constant',\n",
    "    truncate=5,\n",
    "    cval=0\n",
    ")\n",
    "X, Y = np.meshgrid(xedges, yedges)\n",
    "H = gf_func(H)\n",
    "H = H.T/np.amax(H)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm = ax.pcolormesh(X, Y, H, cmap='Reds', vmin=0.0)\n",
    "\n",
    "fig.colorbar(cm)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sdf['PositionX'],sdf['PositionY'], '.r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([(1, 2), (3, 4), (4, 5), (100,100)])\n",
    "tree = spatial.KDTree(np.array(points))\n",
    "radius = 3.0\n",
    "\n",
    "neighbors = tree.query_ball_tree(tree, radius)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csg = Telemetry(\n",
    "        times=df['TimeUTC'],\n",
    "        times_local=df['TimeLocal'],\n",
    "        lons=df['Longitude'],\n",
    "        lats=df['Latitude'],\n",
    "        regions=df['Group'],\n",
    "        df_add=df,\n",
    "        out_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 42\n",
    "gf_func = partial(\n",
    "    gaussian_filter,\n",
    "    sigma=5,\n",
    "    mode='constant',\n",
    "    truncate=5,\n",
    "    cval=0\n",
    ")\n",
    "rdf, rds = csg.get_random_track_segment(\n",
    "    time_len=300,\n",
    "    out_dir=os.path.join(out_dir, f'track_{str(ix)}'),\n",
    "    rnd_seed=ix,\n",
    "    gf_func=gf_func,\n",
    "    max_agl=300,\n",
    "    min_xwidth_km=3,\n",
    "    min_ywidth_km=3,\n",
    "    xpad_km=1.5,\n",
    "    ypad_km=1.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.Agl.quantile(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\n",
    "    'Agl', 'VelocityVer', 'VelocityHor', 'HeadingRate', \n",
    "    'WindLateral80m', 'WindSupport80m', 'WindRelativeAngle80m',#'ElevNearDiff'\n",
    "    'WindDirection80m', 'WindSpeed80m', 'OroSmooth'\n",
    "]\n",
    "fig, ax = plot_sim_tracks_in_space((1,rdf, rds))\n",
    "fig, ax = plot_sim_tracks_in_time((1,rdf, rds), colnames=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.WindSpeed80m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(telemetry_dir, 'csg_ge_vr.prq_tracks_ca_annotated')\n",
    "df = pd.read_parquet(fpath)\n",
    "df['Agl'] = df['Altitude'] - df['GroundElevation']\n",
    "df['HeadingRateRaw'] = df['HeadingRate'].multiply(-1) \n",
    "df['HeadingRate'] = df['HeadingRateRaw'].rolling(3, min_periods=1, center=True).mean().bfill().ffill()\n",
    "df['WindLateral80mAbs'] = df['WindLateral80m'].abs()\n",
    "df.drop(columns=[ix for ix in df.columns if '_var' in ix], inplace=True)\n",
    "df.drop(columns=[ix for ix in df.columns if '10m' in ix], inplace=True)\n",
    "df.drop(columns=[ix for ix in df.columns if 'OroUpdraftD' in ix], inplace=True)\n",
    "csg = Telemetry(\n",
    "    times=df['TimeUTC'],\n",
    "    times_local=df['TimeLocal'],\n",
    "    lons=df['Longitude'],\n",
    "    lats=df['Latitude'],\n",
    "    regions=df['Group'],\n",
    "    df_add=df,\n",
    "    out_dir=output_dir\n",
    ")\n",
    "with open(csg.domain_fpath, 'rb') as outp:\n",
    "    csg.df_subdomains = pickle.load(outp)\n",
    "csg_plotter = TelemetryPlotter(csg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(telemetry_dir, 'csg_ge_vr.prq_tracks')\n",
    "vdf = pd.read_parquet(fpath, engine='fastparquet')\n",
    "vcsg = Telemetry(\n",
    "    times=vdf['TimeUTC'],\n",
    "    times_local=vdf['TimeLocal'],\n",
    "    lons=vdf['Longitude'],\n",
    "    lats=vdf['Latitude'],\n",
    "    regions=vdf['Group'],\n",
    "    df_add=vdf,\n",
    "    out_dir=output_dir\n",
    ")\n",
    "vcsg_plotter = TelemetryPlotter(vcsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,3))\n",
    "track_id = 812\n",
    "cname='PositionX'\n",
    "csg_plotter.plot_track_in_time(track_id, cname, '.r', ax=ax)\n",
    "vcsg_plotter.plot_track_in_time(track_id, cname, '-b', ax=ax)\n",
    "#ax.set_xlim([150,190])\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,3))\n",
    "track_id = 199\n",
    "csg_plotter.plot_track_in_space(track_id,  '-r', ax=ax)\n",
    "vcsg_plotter.plot_track_in_space(track_id,  '-b', ax=ax)\n",
    "#ax.set_xlim([150,190])\n",
    "ax.grid(True)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_func = partial(\n",
    "        gaussian_filter,\n",
    "        sigma=5,\n",
    "        mode='constant',\n",
    "        truncate=5,\n",
    "        cval=0\n",
    "    )\n",
    "dfs, ds = csg.get_random_track_segment(\n",
    "    time_len=300, \n",
    "    rnd_seed=1, \n",
    "    out_dir=output_dir,\n",
    "    gf_func=gf_func,\n",
    "    min_xwidth_km=3,\n",
    "    min_ywidth_km=3,\n",
    "    xpad_km=1.5,\n",
    "    ypad_km=1.5\n",
    ")\n",
    "#list(ds.data_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(8,3))\n",
    "ax=ax.flatten()\n",
    "cm = ax[0].pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain', alpha=0.15)\n",
    "cm = ax[0].scatter(dfs['PositionX'],dfs['PositionY'],c=dfs['Agl'], s=0.4, cmap='Reds_r')\n",
    "ax[0].plot(dfs['PositionX'].iloc[0], dfs['PositionY'].iloc[0], '*g')\n",
    "cb = fig.colorbar(cm, ax=ax[0], label='AGL [m]')\n",
    "cm = ax[1].pcolormesh(ds.x.values, ds.y.values, ds['OroSmooth'], cmap='viridis', alpha=0.5)\n",
    "cb = fig.colorbar(cm, ax=ax[1], label='OroUpdraft [m/s]')\n",
    "# cm = ax[2].pcolormesh(ds.x.values, ds.y.values, ds['WindDirection_80m'], cmap='viridis', alpha=0.5)\n",
    "# cb = fig.colorbar(cm, ax=ax[2], label='Wind Direction [deg]')\n",
    "# cm = ax[3].pcolormesh(ds.x.values, ds.y.values, ds['WindSpeed_80m'], cmap='viridis', alpha=0.5)\n",
    "# cb = fig.colorbar(cm, ax=ax[3], label='Wind Speed [m/s]')\n",
    "for iax in ax:\n",
    "    iax.axis('off')\n",
    "    iax.set_aspect('equal')\n",
    "#ax[0].plot(dfs['PositionX'], dfs['PositionY'], '-r')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, 'fitted_models_ca.pickle'), 'rb') as outp:\n",
    "    models= pickle.load(outp)\n",
    "with open(os.path.join(output_dir, 'fitted_models_ca_std_funcs.pickle'), 'rb') as outp:\n",
    "    std_funcs= pickle.load(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.loc['Covariates','VelocityHorNextStd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tracks = 5\n",
    "time_lags = [5, 10, 20]\n",
    "lag_cols = [ix.split('Next')[0] for ix in models.columns]\n",
    "num_steps = int(dfs['TrackTimeElapsed'].iloc[-1])\n",
    "xlocs = np.random.normal(loc=dfs['PositionX'].iloc[0], scale=25., size=num_tracks)\n",
    "ylocs = np.random.normal(loc=dfs['PositionY'].iloc[0], scale=25., size=num_tracks)\n",
    "zlocs = np.random.normal(loc=dfs['Altitude'].iloc[0], scale=5., size=num_tracks)\n",
    "start_state = {'TrackTimeElapsed':0.}\n",
    "start_state |= {'Heading':dfs['Heading'].iloc[0]}\n",
    "start_state |= {ix:dfs[ix].iloc[0] for ix in lag_cols}\n",
    "start_state |= {f'{ix}Lag{iy}':dfs[ix].iloc[0] for ix in lag_cols for iy in time_lags}\n",
    "start_state |= {f'{ix}Lag{iy}':0. for ix in lag_cols for iy in time_lags}\n",
    "list_of_start_states = []\n",
    "for xloc, yloc, zloc in zip(xlocs,ylocs,zlocs):\n",
    "    istate = deepcopy(start_state)\n",
    "    istate |= {'PositionX': xloc, 'PositionY': yloc, 'Altitude': zloc}\n",
    "    list_of_start_states.append(istate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# istate = deepcopy(list_of_start_states[3])\n",
    "# dist_dict = {'Near': [25,50,75], 'Mid': [400,500,600], 'Far': [900,1000,1100]}\n",
    "# angle_dict = {'L30':-30, 'R30':30}\n",
    "# if 'GroundElevation' in list(ds.data_vars.keys()):\n",
    "#     ds = ds.rename({'GroundElevation':'Elev'})\n",
    "# istate = annotate_env_conditions(istate, ds, dist_dict, angle_dict)\n",
    "# istate = process_wind_conditions(istate, 80.)\n",
    "# istate = annotate_lookahead_conditions(istate, dist_dict, np.mean, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    rfunc = partial(generate_track, ds=ds, models=models, std_funcs=std_funcs, \n",
    "                    num_steps=300, mtype='LinReg', verbose=False)\n",
    "    results = run_loop(rfunc,list_of_start_states, ncores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(8,3))\n",
    "ax=ax.flatten()\n",
    "cm = ax[0].pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain', alpha=0.15)\n",
    "cm = ax[0].scatter(dfs['PositionX'],dfs['PositionY'],c=dfs['Agl'], s=0.4, cmap='Reds_r')\n",
    "ax[0].plot(dfs['PositionX'].iloc[0], dfs['PositionY'].iloc[0], '*g')\n",
    "for simdf in results:\n",
    "    ax[0].plot(simdf['PositionX'], simdf['PositionY'], '-b', alpha=0.75,linewidth=0.5)\n",
    "    \n",
    "cb = fig.colorbar(cm, ax=ax[0], label='AGL [m]')\n",
    "cm = ax[1].pcolormesh(ds.x.values, ds.y.values, ds['OroSmooth'], cmap='viridis', alpha=0.5)\n",
    "cb = fig.colorbar(cm, ax=ax[1], label='OroUpdraft [m/s]')\n",
    "# cm = ax[2].pcolormesh(ds.x.values, ds.y.values, ds['WindDirection_80m'], cmap='viridis', alpha=0.5)\n",
    "# cb = fig.colorbar(cm, ax=ax[2], label='Wind Direction [deg]')\n",
    "# cm = ax[3].pcolormesh(ds.x.values, ds.y.values, ds['WindSpeed_80m'], cmap='viridis', alpha=0.5)\n",
    "# cb = fig.colorbar(cm, ax=ax[3], label='Wind Speed [m/s]')\n",
    "for iax in ax:\n",
    "    iax.axis('off')\n",
    "    iax.set_aspect('equal')\n",
    "#ax[0].plot(dfs['PositionX'], dfs['PositionY'], '-r')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(12, 8), sharex=True)\n",
    "ax = ax.flatten()\n",
    "cols_to_plot = [\n",
    "    'VelocityVer', 'VelocityHor','HeadingRate',\n",
    "    'Agl', 'Heading',\n",
    "    'Altitude','PositionX','PositionY',\n",
    "    #'OroSmooth', 'WindSupport80m', \n",
    "]\n",
    "for i, iname in enumerate(cols_to_plot):\n",
    "    for simdf in results:\n",
    "        ax[i].plot(simdf['TrackTimeElapsed'], simdf[iname], '-b', linewidth=0.8, alpha=0.5)\n",
    "        ax[i].set_ylabel(iname)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j, iloc in enumerate(start_locs):\n",
    "    print(f'{j}', end=\"-\", flush=True)\n",
    "    simdf = []\n",
    "    cur_state = deepcopy(start_state)\n",
    "    xloc, yloc, zloc = deepcopy(iloc)\n",
    "    cur_state |= {'PositionX':xloc, 'PositionY':yloc, 'AltitudeAgl':zloc}\n",
    "    cur_state = annotate_state_with_env_covariates(ds, cur_state, southwest)\n",
    "    simdf.append(deepcopy(cur_state))\n",
    "    new_state = deepcopy(cur_state)\n",
    "    for i in range(num_pred_steps):\n",
    "        new_state['Heading'] = add_angles(cur_state['Heading'], cur_state['HeadingRate'])\n",
    "        new_state['PositionX'] = cur_state['PositionX'] + np.cos(np.radians(cur_state['Heading']))*cur_state['VelocityHor']\n",
    "        new_state['PositionY'] = cur_state['PositionY'] + np.sin(np.radians(cur_state['Heading']))*cur_state['VelocityHor']\n",
    "        new_state['AltitudeAgl'] = cur_state['AltitudeAgl'] + cur_state['VelocityVer']\n",
    "        for icol in list(models.columns):\n",
    "            snames = models.loc['covariates', icol]\n",
    "            vnames = [ix.split('Std')[0] for ix in snames]\n",
    "            input_std=[]\n",
    "            for ix,iy in zip(snames, vnames):\n",
    "                input_std.append(std_funcs[ix].transform(np.atleast_2d(cur_state[iy]))[0][0])\n",
    "            #print(np.atleast_2d(input_std).shape)\n",
    "            input_std_poly = models.loc['poly_func',icol].transform(np.atleast_2d(input_std))\n",
    "            output_std = models.loc[reg_type, icol].predict(np.atleast_2d(input_std_poly))\n",
    "            new_state[icol.split('Next')[0]] = std_funcs[icol].inverse_transform(np.atleast_2d(output_std))[0]\n",
    "            #new_state[icol.split('Next')[0]] = models.loc[reg_type, icol].predict(poly_list)\n",
    "        new_state['TrackTimeElapsed'] = deepcopy(cur_state['TrackTimeElapsed']) + 1.\n",
    "        if reached_the_edge(new_state, width):\n",
    "            break\n",
    "        new_state = annotate_state_with_env_covariates(ds, new_state, southwest)\n",
    "        for ilag in tlags:\n",
    "            if new_state['TrackTimeElapsed']-start_time==ilag:\n",
    "                for icol in lag_cols:\n",
    "                    new_state[f'{icol}{str(int(ilag))}ago'] = simdf[-ilag][icol]\n",
    "        simdf.append(deepcopy(new_state))\n",
    "        cur_state = deepcopy(new_state)\n",
    "    simdf = pd.DataFrame(simdf)\n",
    "    list_of_simdf.append(simdf)\n",
    "    \n",
    "    #print(xloc, yloc, zloc)\n",
    "#     cur_state['DriftHor'] = np.sqrt(cur_state['DriftX']**2 + cur_state['DriftY']**2)\n",
    "#     cur_state['DriftHeading'] = np.arctan2(cur_state['DriftX'], cur_state['DriftY'])\n",
    "#     cur_elev = ds['GroundElevation'].sel(x=cur_state['PositionX'],y=cur_state['PositionY'], method='nearest')\n",
    "#     cur_state['AltitudeAGL'] = cur_state['PositionZ'] - cur_elev\n",
    "#     cur_state['TimeElapsed'] = 0.\n",
    "#     simdf = []\n",
    "#     #print(cur_state)\n",
    "#     for i in range(int(sim_time_duration)):\n",
    "\n",
    "# #         # propogate\n",
    "#         cur_state_list = [cur_state[iname] for iname in states]\n",
    "#         new_state_list = np.random.multivariate_normal(\n",
    "#             mm.func_f(cur_state_list),\n",
    "#             mm.func_Q(cur_state_list)\n",
    "#         )\n",
    "#         new_state = {k: new_state_list[i] for i, k in enumerate(states)}\n",
    "# #         if i % 30 == 0:\n",
    "# #             idx = dftrack['TrackTimeElapsed'].sub(i).abs().idxmin()\n",
    "# # #             new_state['DriftX'] = cur_state['DriftX'] + 0.01*(dftrack.loc[idx, 'PositionX'] - new_state['PositionX'])\n",
    "# # #             new_state['DriftY'] = cur_state['DriftX'] + 0.01*(dftrack.loc[idx, 'PositionY'] - new_state['PositionY'])\n",
    "# #             new_state['PositionX'] = dftrack.loc[idx, 'PositionX']\n",
    "# #             new_state['PositionY'] = dftrack.loc[idx, 'PositionY']\n",
    "#         new_state['DriftHor'] = np.sqrt(new_state['DriftX']**2 + new_state['DriftY']**2)\n",
    "#         new_state['DriftHeading'] = np.arctan2(new_state['DriftX'], new_state['DriftY'])\n",
    "#         new_state['TimeElapsed'] = cur_state['TimeElapsed'] + mm.dt\n",
    "# #         new_elev = ds['GroundElevation'].sel(x=new_state['PositionX'],y=new_state['PositionY'], method='nearest')\n",
    "# #         new_state['AltitudeAGL'] = new_state['PositionZ'] - new_elev\n",
    "        \n",
    "# #         new_state['PositionX'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "# #                                                   drop=True).squeeze().x.values\n",
    "# #         new_state['PositionY'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "# #                                                   drop=True).squeeze().y.values\n",
    "#         cur_state = deepcopy(new_state)\n",
    "#         simdf.append(new_state)\n",
    "        \n",
    "#         # stopping criterion\n",
    "#         stop_criterion = (new_state['PositionX'] > ds.x.max().values)\n",
    "#         stop_criterion = stop_criterion | (new_state['PositionX'] < ds.x.min().values)\n",
    "#         stop_criterion = stop_criterion | (new_state['PositionY'] < ds.y.min().values)\n",
    "#         stop_criterion = stop_criterion | (new_state['PositionY'] > ds.y.max().values)\n",
    "#         if stop_criterion:\n",
    "#             break\n",
    "#     list_of_simdfs.append(pd.DataFrame(simdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "cm = ax.pcolormesh(ds.x.values-southwest[0], ds.y.values-southwest[1], \n",
    "                   ds['GroundElevation'], cmap='terrain', alpha=0.15)\n",
    "cm = ax.scatter(dfs['PositionX']-southwest[0],\n",
    "                dfs['PositionY']-southwest[1],\n",
    "                c=dfs['AltitudeAgl'], s=0.4, cmap='Reds_r', vmin=0, vmax=200)\n",
    "cb = fig.colorbar(cm, ax=ax, label='AGL [m]')\n",
    "ax.plot(dfs['PositionX'].iloc[0]-southwest[0], dfs['PositionY'].iloc[0]-southwest[1], '*g')\n",
    "ax.set_aspect('equal')\n",
    "for simdf in list_of_simdf:\n",
    "    ax.plot(simdf['PositionX'], simdf['PositionY'], '-b', alpha=0.75,linewidth=0.1)\n",
    "    cm = ax.scatter(simdf['PositionX'], simdf['PositionY'], c=simdf['AltitudeAgl'], \n",
    "                    s=0.2, cmap='Blues_r', vmin=0, vmax=200)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_simdf[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for icol in list(models.columns):\n",
    "        covs_needed = [ix.split('Std')[0] for ix in models.loc['covariates', icol]]\n",
    "        print(icol, '\\n', covs_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pad=100\n",
    "start_bounds = (dfs['PositionX'].iloc[0]-ds.x.min().item()-pad, \n",
    "                dfs['PositionX'].iloc[0]-ds.x.min().item()+pad,\n",
    "                dfs['PositionY'].iloc[0]-ds.y.min().item()-pad,\n",
    "                dfs['PositionY'].iloc[0]-ds.y.min().item()+pad)\n",
    "start_bounds = [ix/1000. for ix in start_bounds]\n",
    "xdiff = dfs['PositionX'].iloc[-1]-dfs['PositionX'].iloc[0]\n",
    "ydiff = dfs['PositionY'].iloc[-1]-dfs['PositionY'].iloc[0]\n",
    "track_dirn = np.degrees(np.arctan2(xdiff,ydiff))\n",
    "southwest_lonlat = ccrs.CRS(csg.geo_crs).transform_points(\n",
    "    x=np.array([ds.x.min().item()]),\n",
    "    y=np.array([ds.y.min().item()]),\n",
    "    src_crs=ccrs.CRS(csg.proj_crs)\n",
    ")[0][:2]\n",
    "print(southwest_lonlat)\n",
    "config_wy_snapshot = Config(\n",
    "    run_name='run_test',\n",
    "    southwest_lonlat=(southwest_lonlat[0], southwest_lonlat[1]), \n",
    "    region_width_km=(5,5),\n",
    "    resolution=10.,\n",
    "    # simulation parameters\n",
    "    sim_mode='uniform',\n",
    "    uniform_winddirn=ds.WindDirection_80m.median().item()%360,\n",
    "    uniform_windspeed=ds.WindSpeed_80m.median().item()%360,\n",
    "    track_direction=track_dirn,\n",
    "    track_count = 100,\n",
    "    track_start_region=start_bounds,\n",
    "    updraft_threshold = 0.,\n",
    "    #smooth_threshold_cutoff=True\n",
    ")\n",
    "sim = Simulator(config_wy_snapshot)\n",
    "sim.simulate_tracks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = sim.plot_terrain_elevation(show=True)\n",
    "cm = ax.scatter(dfs['PositionX'],dfs['PositionY'],c=dfs['AltitudeAgl'], s=0.4, cmap='Reds_r')\n",
    "ax.plot(dfs['PositionX'].iloc[0], dfs['PositionY'].iloc[0], '*g')\n",
    "#sim.plot_directional_potentials(show=True)\n",
    "#sim.plot_simulated_tracks(show=True)\n",
    "fig, ax = sim.plot_presence_map(show=True, radius=100.)\n",
    "ax.plot(dfs['PositionX'].iloc[0], dfs['PositionY'].iloc[0], '*g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5,5))\n",
    "#cm1 = ax.pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain', alpha=0.5)\n",
    "cm1 = ax.pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraftSmooth'], cmap='terrain', alpha=0.5)\n",
    "#ax.plot(dftrack['PositionX'],dftrack['PositionY'],'-r')\n",
    "cm2 = ax.scatter(dftrack['PositionX'],dftrack['PositionY'],c=dftrack['AltitudeAgl'], s=0.4, cmap='Reds_r')\n",
    "cb = fig.colorbar(cm1, ax=ax, label='Ground Elevation [m]')\n",
    "cb2 = fig.colorbar(cm2, ax=ax, label='Altitude AGL [m]')\n",
    "ax.set_aspect('equal')\n",
    "ax.axis(False)\n",
    "pad=100\n",
    "# ax.set_xlim([dftrack['PositionX'].min()-pad, dftrack['PositionX'].max()+pad])\n",
    "# ax.set_ylim([dftrack['PositionY'].min()-pad, dftrack['PositionY'].max()+pad])\n",
    "# cm = ax[1].pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraftS'], cmap='viridis', vmin=0, vmax=1.)\n",
    "# cb = fig.colorbar(cm, ax=ax[1])\n",
    "#ax[1].set_aspect('equal')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "list_of_simdfs = []\n",
    "points_list = []\n",
    "look_ahead_conditions = [(50,-25), (50,-45), (50,0), (50,-25), (50,45)]\n",
    "# look_ahead_conditions = [(4,-45), (4,-30), (4,-20), (4,-10), (4,-5), (4,0), \n",
    "#                          (4,5), (4,10), (4,20), (4,30), (4,45)] # assuming 10 m \n",
    "look_ahead_scales = [1/(180-abs(ix)) for _,ix in look_ahead_conditions]\n",
    "for j in range(len(start_state_list)):\n",
    "    print(f'{j}', end=\"-\")\n",
    "    np.random.seed()\n",
    "    cur_state = deepcopy(start_state_list[j])\n",
    "    cur_state['DriftHor'] = np.sqrt(cur_state['DriftX']**2 + cur_state['DriftY']**2)\n",
    "    cur_state['DriftHeading'] = np.arctan2(cur_state['DriftX'], cur_state['DriftY'])\n",
    "    cur_elev = ds['GroundElevation'].sel(x=cur_state['PositionX'],y=cur_state['PositionY'], method='nearest')\n",
    "    cur_state['AltitudeAGL'] = cur_state['PositionZ'] - cur_elev\n",
    "    cur_state['TimeElapsed'] = 0.\n",
    "    simdf = []\n",
    "    #print(cur_state)\n",
    "    for i in range(int(sim_time_duration)):\n",
    "\n",
    "#         # propogate\n",
    "        cur_state_list = [cur_state[iname] for iname in states]\n",
    "        new_state_list = np.random.multivariate_normal(\n",
    "            mm.func_f(cur_state_list),\n",
    "            mm.func_Q(cur_state_list)\n",
    "        )\n",
    "        new_state = {k: new_state_list[i] for i, k in enumerate(states)}\n",
    "#         if i % 30 == 0:\n",
    "#             idx = dftrack['TrackTimeElapsed'].sub(i).abs().idxmin()\n",
    "# #             new_state['DriftX'] = cur_state['DriftX'] + 0.01*(dftrack.loc[idx, 'PositionX'] - new_state['PositionX'])\n",
    "# #             new_state['DriftY'] = cur_state['DriftX'] + 0.01*(dftrack.loc[idx, 'PositionY'] - new_state['PositionY'])\n",
    "#             new_state['PositionX'] = dftrack.loc[idx, 'PositionX']\n",
    "#             new_state['PositionY'] = dftrack.loc[idx, 'PositionY']\n",
    "        new_state['DriftHor'] = np.sqrt(new_state['DriftX']**2 + new_state['DriftY']**2)\n",
    "        new_state['DriftHeading'] = np.arctan2(new_state['DriftX'], new_state['DriftY'])\n",
    "        new_state['TimeElapsed'] = cur_state['TimeElapsed'] + mm.dt\n",
    "#         new_elev = ds['GroundElevation'].sel(x=new_state['PositionX'],y=new_state['PositionY'], method='nearest')\n",
    "#         new_state['AltitudeAGL'] = new_state['PositionZ'] - new_elev\n",
    "        \n",
    "#         new_state['PositionX'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "#                                                   drop=True).squeeze().x.values\n",
    "#         new_state['PositionY'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "#                                                   drop=True).squeeze().y.values\n",
    "        cur_state = deepcopy(new_state)\n",
    "        simdf.append(new_state)\n",
    "        \n",
    "        # stopping criterion\n",
    "        stop_criterion = (new_state['PositionX'] > ds.x.max().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionX'] < ds.x.min().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionY'] < ds.y.min().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionY'] > ds.y.max().values)\n",
    "        if stop_criterion:\n",
    "            break\n",
    "    list_of_simdfs.append(pd.DataFrame(simdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_short(xloc, yloc, ds, radius=100):\n",
    "    xbounds = (xloc-radius, xloc+radius)\n",
    "    ybounds = (yloc-radius, yloc+radius)\n",
    "    mask = (ds.x<xbounds[1]) & (ds.x>xbounds[0]) & (ds.y>ybounds[0]) & (ds.y<ybounds[1]) \n",
    "    ds_short = ds.where(mask, drop=True)\n",
    "    xmesh, ymesh = np.meshgrid(ds_short.x-xloc, ds_short.y-yloc)\n",
    "    grid_shape = xmesh.shape\n",
    "    mov_model = MovModel(45., grid_shape)\n",
    "    row_inds, col_inds = np.indices(grid_shape)\n",
    "    node_ids = row_inds + col_inds*grid_shape[0]\n",
    "    bndry_condn = np.empty_like(node_ids, dtype=float)\n",
    "    bndry_condn[:] = np.nan\n",
    "    bndry_condn[xmesh**2 + ymesh**2 > radius**2] = 0\n",
    "    bndry_condn[xmesh**2 + ymesh**2 < 20**2] = 10\n",
    "    bndry_nodes = node_ids[~np.isnan(bndry_condn)]\n",
    "    bndry_energy = bndry_condn[~np.isnan(bndry_condn)]\n",
    "    sparse_row_inds, sparse_col_inds, sparse_facs = mov_model.assemble_sparse_linear_system()\n",
    "    potential = mov_model.solve_sparse_linear_system(\n",
    "        ds_short['OroUpdraft'].values,\n",
    "        bndry_nodes,\n",
    "        bndry_energy,\n",
    "        sparse_row_inds,\n",
    "        sparse_col_inds,\n",
    "        sparse_facs\n",
    "    )\n",
    "    ds_short['Potential'] = (('y', 'x'), potential)\n",
    "    return ds_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = {\n",
    "            'PositionX': dftrack['PositionX'].iloc[0],\n",
    "            'PositionY': dftrack['PositionY'].iloc[0],\n",
    "            'VelocityX': dftrack['VelocityX_TU'].iloc[0],\n",
    "            'VelocityY':dftrack['VelocityY_TU'].iloc[0],\n",
    "            'DriftX': 0.1*dftrack['VelocityX_TU'].iloc[0],\n",
    "            'DriftY':dftrack['VelocityY_TU'].iloc[0],\n",
    "            'LogTauHor': -10.,\n",
    "            'Omega': .01,\n",
    "            'PositionZ': 1000.,\n",
    "            'VelocityZ': 0.,\n",
    "            'DriftZ': 0.,\n",
    "            'LogTauVer': -50.,\n",
    "\n",
    "        }\n",
    "mm = CVM3D_NL_4()\n",
    "mm.dt = 1.\n",
    "mm.phi = {\n",
    "    'eta_hor': 5.0,\n",
    "    'sigma_log_tau_hor': 1.5,\n",
    "    'sigma_mu_hor': 0.5,\n",
    "    'sigma_omega': 0.25,\n",
    "    'eta_ver': 0.1,\n",
    "    'sigma_log_tau_ver': 0.1,\n",
    "    'sigma_mu_ver': 0.1\n",
    "}\n",
    "num_tracks = 20\n",
    "start_position_std = 1.\n",
    "tdiff = dftrack.TrackTimeElapsed.iloc[-1] - dftrack.TrackTimeElapsed.iloc[0]\n",
    "time_list = np.linspace(dftrack.TrackTimeElapsed.iloc[0], \n",
    "                        dftrack.TrackTimeElapsed.iloc[-1], \n",
    "                        int(tdiff/30)+1)\n",
    "indices = [dftrack['TrackTimeElapsed'].sub(itime).abs().idxmin() for itime in time_list]\n",
    "sim_time_duration = 50#dftrack.TrackTimeElapsed.iloc[-1]\n",
    "start_state_list = []\n",
    "for idx in indices:\n",
    "    this_start_state = deepcopy(start_state)\n",
    "    for _ in range(num_tracks):\n",
    "        this_start_state['PositionX'] = dftrack.loc[idx, 'PositionX']\n",
    "        this_start_state['PositionY'] = dftrack.loc[idx, 'PositionY']\n",
    "        this_start_state['VelocityX'] = dftrack.loc[idx, 'VelocityX']\n",
    "        this_start_state['VelocityY'] = dftrack.loc[idx, 'VelocityY']\n",
    "        this_start_state['DriftX'] = 0.5*dftrack.loc[idx, 'VelocityX']\n",
    "        this_start_state['DriftY'] = 0.5*dftrack.loc[idx, 'VelocityY']\n",
    "        start_state_list.append(this_start_state)\n",
    "states = mm.state_names\n",
    "len(start_state_list)\n",
    "#print(time_list)\n",
    "#start_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "list_of_simdfs = []\n",
    "points_list = []\n",
    "look_ahead_conditions = [(50,-25), (50,-45), (50,0), (50,-25), (50,45)]\n",
    "# look_ahead_conditions = [(4,-45), (4,-30), (4,-20), (4,-10), (4,-5), (4,0), \n",
    "#                          (4,5), (4,10), (4,20), (4,30), (4,45)] # assuming 10 m \n",
    "look_ahead_scales = [1/(180-abs(ix)) for _,ix in look_ahead_conditions]\n",
    "for j in range(len(start_state_list)):\n",
    "    print(f'{j}', end=\"-\")\n",
    "    np.random.seed()\n",
    "    cur_state = deepcopy(start_state_list[j])\n",
    "    cur_state['DriftHor'] = np.sqrt(cur_state['DriftX']**2 + cur_state['DriftY']**2)\n",
    "    cur_state['DriftHeading'] = np.arctan2(cur_state['DriftX'], cur_state['DriftY'])\n",
    "    cur_elev = ds['GroundElevation'].sel(x=cur_state['PositionX'],y=cur_state['PositionY'], method='nearest')\n",
    "    cur_state['AltitudeAGL'] = cur_state['PositionZ'] - cur_elev\n",
    "    cur_state['TimeElapsed'] = 0.\n",
    "    simdf = []\n",
    "    #print(cur_state)\n",
    "    for i in range(int(sim_time_duration)):\n",
    "\n",
    "#         # propogate\n",
    "        cur_state_list = [cur_state[iname] for iname in states]\n",
    "        new_state_list = np.random.multivariate_normal(\n",
    "            mm.func_f(cur_state_list),\n",
    "            mm.func_Q(cur_state_list)\n",
    "        )\n",
    "        new_state = {k: new_state_list[i] for i, k in enumerate(states)}\n",
    "#         if i % 30 == 0:\n",
    "#             idx = dftrack['TrackTimeElapsed'].sub(i).abs().idxmin()\n",
    "# #             new_state['DriftX'] = cur_state['DriftX'] + 0.01*(dftrack.loc[idx, 'PositionX'] - new_state['PositionX'])\n",
    "# #             new_state['DriftY'] = cur_state['DriftX'] + 0.01*(dftrack.loc[idx, 'PositionY'] - new_state['PositionY'])\n",
    "#             new_state['PositionX'] = dftrack.loc[idx, 'PositionX']\n",
    "#             new_state['PositionY'] = dftrack.loc[idx, 'PositionY']\n",
    "        new_state['DriftHor'] = np.sqrt(new_state['DriftX']**2 + new_state['DriftY']**2)\n",
    "        new_state['DriftHeading'] = np.arctan2(new_state['DriftX'], new_state['DriftY'])\n",
    "        new_state['TimeElapsed'] = cur_state['TimeElapsed'] + mm.dt\n",
    "#         new_elev = ds['GroundElevation'].sel(x=new_state['PositionX'],y=new_state['PositionY'], method='nearest')\n",
    "#         new_state['AltitudeAGL'] = new_state['PositionZ'] - new_elev\n",
    "        \n",
    "#         new_state['PositionX'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "#                                                   drop=True).squeeze().x.values\n",
    "#         new_state['PositionY'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "#                                                   drop=True).squeeze().y.values\n",
    "        cur_state = deepcopy(new_state)\n",
    "        simdf.append(new_state)\n",
    "        \n",
    "        # stopping criterion\n",
    "        stop_criterion = (new_state['PositionX'] > ds.x.max().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionX'] < ds.x.min().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionY'] < ds.y.min().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionY'] > ds.y.max().values)\n",
    "        if stop_criterion:\n",
    "            break\n",
    "    list_of_simdfs.append(pd.DataFrame(simdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cm1 = ax.pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='gray', alpha=0.25)\n",
    "cb = fig.colorbar(cm1, ax=ax, label='Ground Elevation [m]', pad=0.01, shrink=0.85, aspect=30)\n",
    "ax.plot(dftrack['PositionX'],dftrack['PositionY'],'-r', label='Telemetry Track')\n",
    "# cm2 = ax.scatter(dftrack['PositionX'],dftrack['PositionY'],c=dftrack['AltitudeAGL'], \n",
    "#                  s=0.4, cmap='Reds_r', label='Telemetry Track')\n",
    "# cb2 = fig.colorbar(cm2, ax=ax, label='Altitude AGL [m]')\n",
    "for simdf in list_of_simdfs:\n",
    "    #ax.plot(simdf['PositionX'], simdf['PositionY'], '.-b', alpha=0.5, zorder=1000, linewidth=0.2)\n",
    "    ax.plot(simdf['PositionX'], simdf['PositionY'], '.b', alpha=0.15,markersize=0.1)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis(False)\n",
    "ax.legend()\n",
    "# cm = ax[1].pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraftS'], cmap='viridis', vmin=0, vmax=1.)\n",
    "# cb = fig.colorbar(cm, ax=ax[1])\n",
    "#ax[1].set_aspect('equal')\n",
    "pad=100\n",
    "# ax.set_xlim([dftrack.PositionX.min()-pad,dftrack.PositionX.max()+pad])\n",
    "# ax.set_ylim([dftrack.PositionY.min()-pad,dftrack.PositionY.max()+pad])\n",
    "fig.tight_layout()\n",
    "#ax.set_title('Bayesian Model: Golden Eagle Simulator')\n",
    "fig.savefig(os.path.join(fig_dir, f'bssm_pred_{dftrack.TrackID.iloc[0]}_5.png'), dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = {\n",
    "            'PositionX': dftrack['PositionX'].iloc[0],\n",
    "            'PositionY': dftrack['PositionY'].iloc[0],\n",
    "            'VelocityX': dftrack['VelocityX_TU'].iloc[0],\n",
    "            'VelocityY':dftrack['VelocityY_TU'].iloc[0],\n",
    "            'DriftX': dftrack['VelocityX_TU'].iloc[0],\n",
    "            'DriftY':dftrack['VelocityY_TU'].iloc[0],\n",
    "            'LogTauHor': -20.,\n",
    "            'Omega': .1,\n",
    "            'PositionZ': 1000.,\n",
    "            'VelocityZ': 0.,\n",
    "            'DriftZ': 0.,\n",
    "            'LogTauVer': -50.,\n",
    "\n",
    "        }\n",
    "mm = CVM3D_NL_4()\n",
    "mm.dt = 1.\n",
    "mm.phi = {\n",
    "    'eta_hor': 5.0,\n",
    "    'sigma_log_tau_hor': 1.5,\n",
    "    'sigma_mu_hor': 0.5,\n",
    "    'sigma_omega': 0.25,\n",
    "    'eta_ver': 0.1,\n",
    "    'sigma_log_tau_ver': 0.1,\n",
    "    'sigma_mu_ver': 0.1\n",
    "}\n",
    "num_tracks = 5\n",
    "start_position_std = 5.\n",
    "sim_time_duration = 30\n",
    "start_x = np.random.normal(\n",
    "    loc=start_state['PositionX'],\n",
    "    scale=start_position_std,\n",
    "    size=num_tracks\n",
    ")\n",
    "start_y = np.random.normal(\n",
    "    loc=start_state['PositionY'],\n",
    "    scale=start_position_std,\n",
    "    size=num_tracks\n",
    ")\n",
    "start_state_list = []\n",
    "for ix, iy in zip(start_x, start_y):\n",
    "    this_start_state = deepcopy(start_state)\n",
    "    this_start_state['PositionX'] = ix\n",
    "    this_start_state['PositionY'] = iy\n",
    "    start_state_list.append(this_start_state)\n",
    "states = mm.state_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "list_of_simdfs = []\n",
    "points_list = []\n",
    "look_ahead_conditions = [(50,-25), (50,-45), (50,0), (50,-25), (50,45)]\n",
    "# look_ahead_conditions = [(4,-45), (4,-30), (4,-20), (4,-10), (4,-5), (4,0), \n",
    "#                          (4,5), (4,10), (4,20), (4,30), (4,45)] # assuming 10 m \n",
    "look_ahead_scales = [1/(180-abs(ix)) for _,ix in look_ahead_conditions]\n",
    "for j in range(num_tracks):\n",
    "    print(f'{j}', end=\"-\")\n",
    "    np.random.seed()\n",
    "    cur_state = deepcopy(start_state_list[j])\n",
    "    cur_state['DriftHor'] = np.sqrt(cur_state['DriftX']**2 + cur_state['DriftY']**2)\n",
    "    cur_state['DriftHeading'] = np.arctan2(cur_state['DriftX'], cur_state['DriftY'])\n",
    "    cur_elev = ds['GroundElevation'].sel(x=cur_state['PositionX'],y=cur_state['PositionY'], method='nearest')\n",
    "    cur_state['AltitudeAGL'] = cur_state['PositionZ'] - cur_elev\n",
    "    cur_state['TimeElapsed'] = 0.\n",
    "    simdf = []\n",
    "    #print(cur_state)\n",
    "    for i in range(int(sim_time_duration)):\n",
    "\n",
    "#         # propogate\n",
    "        cur_state_list = [cur_state[iname] for iname in states]\n",
    "        new_state_list = np.random.multivariate_normal(\n",
    "            mm.func_f(cur_state_list),\n",
    "            mm.func_Q(cur_state_list)\n",
    "        )\n",
    "        new_state = {k: new_state_list[i] for i, k in enumerate(states)}\n",
    "        new_state['DriftHor'] = np.sqrt(new_state['DriftX']**2 + new_state['DriftY']**2)\n",
    "        new_state['DriftHeading'] = np.arctan2(new_state['DriftX'], new_state['DriftY'])\n",
    "        new_state['TimeElapsed'] = cur_state['TimeElapsed'] + mm.dt\n",
    "#         new_elev = ds['GroundElevation'].sel(x=new_state['PositionX'],y=new_state['PositionY'], method='nearest')\n",
    "#         new_state['AltitudeAGL'] = new_state['PositionZ'] - new_elev\n",
    "        \n",
    "#         new_state['PositionX'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "#                                                   drop=True).squeeze().x.values\n",
    "#         new_state['PositionY'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "#                                                   drop=True).squeeze().y.values\n",
    "        cur_state = deepcopy(new_state)\n",
    "        simdf.append(new_state)\n",
    "        \n",
    "        # stopping criterion\n",
    "        stop_criterion = (new_state['PositionX'] > ds.x.max().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionX'] < ds.x.min().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionY'] < ds.y.min().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionY'] > ds.y.max().values)\n",
    "        if stop_criterion:\n",
    "            break\n",
    "    list_of_simdfs.append(pd.DataFrame(simdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 2, figsize=(12, 8), sharex=True)\n",
    "ax = ax.flatten()\n",
    "cols_to_plot = list(list_of_simdfs[0].columns)\n",
    "cols_to_plot.remove('TimeElapsed')\n",
    "for i, iname in enumerate(cols_to_plot):\n",
    "    for simdf in list_of_simdfs:\n",
    "        ax[i].plot(simdf['TimeElapsed'], simdf[iname], '.b', linewidth=0.8, alpha=0.5)\n",
    "        ax[i].set_ylabel(iname)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_simdfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsize = 100\n",
    "ds = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        GroundElevation=(['x', 'y',], np.zeros((gridsize,gridsize)))\n",
    "    ),\n",
    "    coords=dict(\n",
    "        x=np.linspace(0,100,gridsize),\n",
    "        y=np.linspace(0,100,gridsize)\n",
    "    ),\n",
    "    attrs=dict(description=\"Synthetic terrain\")\n",
    ")\n",
    "mask = (1.*ds.x + ds.y < 105) & (1.*ds.x + ds.y > 95)\n",
    "mask = mask | ((2.*ds.x + ds.y < 105) & (2.*ds.x + ds.y > 95))\n",
    "ds['GroundElevation'] = xr.where(mask, 5, ds['GroundElevation'])\n",
    "ds['GroundElevation'] = (('y', 'x'), gaussian_filter(ds['GroundElevation'], sigma=1.))\n",
    "slope = calcSlopeDegrees(ds['GroundElevation'].values, res=1.)\n",
    "aspect = calcAspectDegrees(ds['GroundElevation'].values, res=1.)\n",
    "ds['GroundSlope'] = (('y', 'x'), slope)\n",
    "ds['GroundAspect'] = (('y', 'x'), aspect)\n",
    "ds['GroundSlope'].values[ds['GroundElevation'].isnull()] = np.nan\n",
    "ds['GroundAspect'].values[ds['GroundElevation'].isnull()] = np.nan\n",
    "oro_updraft = calcOrographicUpdraft_original(\n",
    "    wspeed=10.,\n",
    "    wdirn=240.,\n",
    "    slope=ds['GroundSlope'].values,\n",
    "    aspect=ds['GroundAspect'].values,\n",
    "    res_terrain=10.,\n",
    "    res=10.\n",
    ")\n",
    "ds['OroUpdraft'] = (('y', 'x'), oro_updraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(8,6))\n",
    "ax=ax.flatten()\n",
    "cm = ax[0].pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain')\n",
    "cb = fig.colorbar(cm, ax=ax[0], pad=0.01, label='elevation')\n",
    "ax[0].set_aspect('equal')\n",
    "cm = ax[1].pcolormesh(ds.x.values, ds.y.values, ds['GroundSlope'], cmap='viridis')\n",
    "cb = fig.colorbar(cm, ax=ax[1], pad=0.01, label='slope')\n",
    "ax[1].set_aspect('equal')\n",
    "cm = ax[2].pcolormesh(ds.x.values, ds.y.values, ds['GroundAspect'], cmap='viridis')\n",
    "cb = fig.colorbar(cm, ax=ax[2], pad=0.01, label='aspect')\n",
    "ax[2].set_aspect('equal')\n",
    "cm = ax[3].pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraft'], cmap='viridis')\n",
    "cb = fig.colorbar(cm, ax=ax[3], pad=0.01, label='Orographic updraft')\n",
    "ax[3].set_aspect('equal')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = {\n",
    "            'PositionX': 20.,\n",
    "            'PositionY': 20.,\n",
    "            'VelocityX': 2.,  # dftrack['VelocityX_TU'].iloc[0],\n",
    "            'VelocityY': 2.,  # dftrack['VelocityY_TU'].iloc[0],\n",
    "            'DriftX': 2.,\n",
    "            'DriftY': 2.,\n",
    "            'LogTauHor': -10.,\n",
    "            'Omega': .0,\n",
    "            'PositionZ': 1000.,\n",
    "            'VelocityZ': 0.,\n",
    "            'DriftZ': 0.,\n",
    "            'LogTauVer': -10.,\n",
    "\n",
    "        }\n",
    "mm = CVM3D_NL_4()\n",
    "mm.dt = 0.1\n",
    "mm.phi = {\n",
    "    'eta_hor': 0.000,\n",
    "    'sigma_log_tau_hor': 0.0001,\n",
    "    'sigma_mu_hor': 0.000,\n",
    "    'sigma_omega': 0.000,\n",
    "    'eta_ver': 0.0001,\n",
    "    'sigma_log_tau_ver': 0.0001,\n",
    "    'sigma_mu_ver': 0.00001\n",
    "}\n",
    "num_tracks = 1\n",
    "start_position_std = 0.\n",
    "sim_time_duration = 200\n",
    "start_x = np.random.normal(\n",
    "    loc=start_state['PositionX'],\n",
    "    scale=start_position_std,\n",
    "    size=num_tracks\n",
    ")\n",
    "start_y = np.random.normal(\n",
    "    loc=start_state['PositionY'],\n",
    "    scale=start_position_std,\n",
    "    size=num_tracks\n",
    ")\n",
    "start_state_list = []\n",
    "for ix, iy in zip(start_x, start_y):\n",
    "    this_start_state = deepcopy(start_state)\n",
    "    this_start_state['PositionX'] = ix\n",
    "    this_start_state['PositionY'] = iy\n",
    "    start_state_list.append(this_start_state)\n",
    "states = mm.state_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_short(xloc, yloc, ds, radius=2):\n",
    "    xbounds = (xloc-radius, xloc+radius)\n",
    "    ybounds = (yloc-radius, yloc+radius)\n",
    "    mask = (ds.x<xbounds[1]) & (ds.x>xbounds[0]) & (ds.y>ybounds[0]) & (ds.y<ybounds[1]) \n",
    "    ds_short = ds.where(mask, drop=True)\n",
    "    xmesh, ymesh = np.meshgrid(ds_short.x-xloc, ds_short.y-yloc)\n",
    "    grid_shape = xmesh.shape\n",
    "    mov_model = MovModel(45., grid_shape)\n",
    "    row_inds, col_inds = np.indices(grid_shape)\n",
    "    node_ids = row_inds + col_inds*grid_shape[0]\n",
    "    bndry_condn = np.empty_like(node_ids, dtype=float)\n",
    "    bndry_condn[:] = np.nan\n",
    "    bndry_condn[xmesh**2 + ymesh**2 > radius**2] = 0\n",
    "    bndry_condn[xmesh**2 + ymesh**2 < 0.5] = 10\n",
    "    bndry_nodes = node_ids[~np.isnan(bndry_condn)]\n",
    "    bndry_energy = bndry_condn[~np.isnan(bndry_condn)]\n",
    "    sparse_row_inds, sparse_col_inds, sparse_facs = mov_model.assemble_sparse_linear_system()\n",
    "    potential = mov_model.solve_sparse_linear_system(\n",
    "        ds_short['OroUpdraft'].values,\n",
    "        bndry_nodes,\n",
    "        bndry_energy,\n",
    "        sparse_row_inds,\n",
    "        sparse_col_inds,\n",
    "        sparse_facs\n",
    "    )\n",
    "    ds_short['Potential'] = (('y', 'x'), potential)\n",
    "    return ds_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_ahead_conditions = [(4,-45), (4,-30), (4,-20), (4,-10), (4,-5), (4,0), \n",
    "                         (4,5), (4,10), (4,20), (4,30), (4,45)] # assuming 10 m \n",
    "look_ahead_conditions = [(2,-45), (2,-30), (2,-20), (2,-10), (2,-5), (2,0), \n",
    "                         (2,5), (2,10), (2,20), (2,30), (2,45)]\n",
    "look_ahead_scales = [(1+abs(ix)) for _,ix in look_ahead_conditions]\n",
    "for ix, iy in zip(look_ahead_conditions, look_ahead_scales):\n",
    "    print(ix, np.around(iy,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_of_simdfs = []\n",
    "points_list = []\n",
    "look_ahead_conditions = [(4,-25), (4,-45), (4,0), (4,-25), (4,45)]\n",
    "look_ahead_conditions = [(4,-45), (4,-30), (4,-20), (4,-10), (4,-5), (4,0), \n",
    "                         (4,5), (4,10), (4,20), (4,30), (4,45)] # assuming 10 m \n",
    "scale = [1/(180-abs(ix)) for _,ix in look_ahead_conditions]\n",
    "#look_ahead_conditions = [(8,-10), (8,-5), (8,0), (8,5), (8,10)]\n",
    "# rot_angle = np.array([\n",
    "#     [45, 0, -45],\n",
    "#     [90, 0, -90],\n",
    "#     [125, 0, -125]\n",
    "# ])\n",
    "for j in range(num_tracks):\n",
    "    print(f'{j}', end=\"-\")\n",
    "    np.random.seed()\n",
    "    cur_state = deepcopy(start_state_list[j])\n",
    "    cur_state['DriftHor'] = np.sqrt(cur_state['DriftX']**2 + cur_state['DriftY']**2)\n",
    "    cur_state['DriftHeading'] = np.arctan2(cur_state['DriftX'], cur_state['DriftY'])\n",
    "    cur_elev = ds['GroundElevation'].sel(x=cur_state['PositionX'],y=cur_state['PositionY'], method='nearest')\n",
    "    cur_state['AltitudeAGL'] = cur_state['PositionZ'] - cur_elev\n",
    "    cur_state['TimeElapsed'] = 0.\n",
    "    simdf = []\n",
    "    #print(cur_state)\n",
    "    for i in range(int(sim_time_duration)):\n",
    "        # change predictable variates\n",
    "        ds_short = get_ds_short(cur_state['PositionX'], cur_state['PositionY'], deepcopy(ds), radius=10)\n",
    "        #print(pot_interp, pot_interp.isel(x=0, y=0))\n",
    "        pot_values = []\n",
    "        for idist, iangle in look_ahead_conditions:\n",
    "            this_point = [\n",
    "                cur_state['PositionX'] + np.cos(cur_state['DriftHeading']+np.radians(iangle))*idist,\n",
    "                cur_state['PositionY'] + np.sin(cur_state['DriftHeading']+np.radians(iangle))*idist,      \n",
    "            ]\n",
    "            pot_value = ds_short['Potential'].interp(x=this_point[0], y=this_point[1], method='linear').values\n",
    "            pot_values.append(pot_value)\n",
    "        #print(np.around(pot_values,4))\n",
    "        move_probs = np.clip(np.array(pot_values), a_min=0.001, a_max=np.Inf)\n",
    "        move_probs = np.multiply(move_probs, look_ahead_scales)\n",
    "        move_probs = np.power(move_probs, -2.0)\n",
    "        move_probs /= np.sum(move_probs)\n",
    "        #print(np.around(move_probs,2))\n",
    "        idx_move = np.random.choice(range(len(move_probs)), p=move_probs)\n",
    "        #idx_min = np.argmin(np.array(pot_values))\n",
    "        _, chosen_angle = look_ahead_conditions[idx_move]\n",
    "        #print(chosen_angle)\n",
    "        cur_state['DriftHeading'] += np.random.normal(np.radians(chosen_angle), 0*np.pi/180)\n",
    "        cur_state['DriftX'] = cur_state['DriftHor']*np.cos(cur_state['DriftHeading'])\n",
    "        cur_state['DriftY'] = cur_state['DriftHor']*np.sin(cur_state['DriftHeading'])\n",
    "        # add stochasticity to it\n",
    "#         points_list.append([point1_x, point1_y])\n",
    "        \n",
    "#         if ds_short['OroUpdraft'].max() > np.random.normal(0.75, 0.01, 1)[0]:\n",
    "#             cur_state['DriftHor'] = 1.#linear functions of potential around current point\n",
    "#             cur_state['DriftHeading'] = -45*np.pi/180.\n",
    "#             cur_state['DriftX'] = cur_state['DriftHor']*np.sin(cur_state['DriftHeading'])\n",
    "#             cur_state['DriftY'] = cur_state['DriftHor']*np.cos(cur_state['DriftHeading'])\n",
    "# #             cur_state['LogTauHor'] = -1.0\n",
    "# #             cur_state['Omega'] = 2*np.pi/180.\n",
    "#         else:\n",
    "#             cur_state['DriftHor'] = 0.5\n",
    "#             #cur_state['DriftHeading'] = 45*np.pi/180.\n",
    "#             cur_state['DriftX'] = cur_state['DriftHor']*np.sin(cur_state['DriftHeading'])\n",
    "#             cur_state['DriftY'] = cur_state['DriftHor']*np.cos(cur_state['DriftHeading'])\n",
    "#             cur_state['LogTauHor'] = -1.0\n",
    "#             cur_state['Omega'] = 10*np.pi/180.\n",
    "        \n",
    "        # propogate\n",
    "        cur_state_list = [cur_state[iname] for iname in states]\n",
    "        new_state_list = np.random.multivariate_normal(\n",
    "            mm.func_f(cur_state_list),\n",
    "            mm.func_Q(cur_state_list)\n",
    "        )\n",
    "        new_state = {k: new_state_list[i] for i, k in enumerate(states)}\n",
    "        new_state['DriftHor'] = np.sqrt(new_state['DriftX']**2 + new_state['DriftY']**2)\n",
    "        new_state['DriftHeading'] = np.arctan2(new_state['DriftX'], new_state['DriftY'])\n",
    "        new_state['TimeElapsed'] = cur_state['TimeElapsed'] + mm.dt\n",
    "        new_elev = ds['GroundElevation'].sel(x=new_state['PositionX'],y=new_state['PositionY'], method='nearest')\n",
    "        new_state['AltitudeAGL'] = new_state['PositionZ'] - new_elev\n",
    "        \n",
    "#         new_state['PositionX'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "#                                                   drop=True).squeeze().x.values\n",
    "#         new_state['PositionY'] = ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), \n",
    "#                                                   drop=True).squeeze().y.values\n",
    "        cur_state = deepcopy(new_state)\n",
    "        simdf.append(new_state)\n",
    "        \n",
    "        # stopping criterion\n",
    "        stop_criterion = (new_state['PositionX'] > ds.x.max().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionX'] < ds.x.min().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionY'] < ds.y.min().values)\n",
    "        stop_criterion = stop_criterion | (new_state['PositionY'] > ds.y.max().values)\n",
    "        if stop_criterion:\n",
    "            break\n",
    "    list_of_simdfs.append(pd.DataFrame(simdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "#cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain', alpha=0.5)\n",
    "cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraft'], cmap='Reds', alpha=0.5, vmax=1.)\n",
    "cb = fig.colorbar(cm, ax=ax, pad=0.01, label='OroUpdraft')\n",
    "for simdf in list_of_simdfs:\n",
    "    #ax.plot(simdf['PositionX'], simdf['PositionY'], '.-b', alpha=0.5, zorder=1000, linewidth=0.2)\n",
    "    ax.plot(simdf['PositionX'], simdf['PositionY'], '-b', alpha=0.5, zorder=1000, linewidth=0.9)\n",
    "cm = ax.pcolormesh(ds_short.x.values, ds_short.y.values, ds_short['Potential'], \n",
    "                  cmap='viridis', alpha=0.5)\n",
    "ax.set_aspect('equal')\n",
    "#ax.plot(points_list[:,0], points_list[:,1], '*k')\n",
    "ax.set_xlim([ds.x.min(), ds.x.max()])\n",
    "ax.set_ylim([ds.y.min(), ds.y.max()])\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "# ax.set_xlim([ds_short.x.min(), ds_short.x.max()])\n",
    "# ax.set_ylim([ds_short.y.min(), ds_short.y.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 2, figsize=(12, 8), sharex=True)\n",
    "ax = ax.flatten()\n",
    "cols_to_plot = list(list_of_simdfs[0].columns)\n",
    "cols_to_plot.remove('TimeElapsed')\n",
    "for i, iname in enumerate(cols_to_plot):\n",
    "    for simdf in list_of_simdfs:\n",
    "        ax[i].plot(simdf['TimeElapsed'], simdf[iname], '.b', linewidth=0.8, alpha=0.5)\n",
    "        ax[i].set_ylabel(iname)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xloc, yloc = (28, 28)\n",
    "ds_short = get_ds_short(xloc, yloc, ds, radius=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "#cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain', alpha=0.5)\n",
    "cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraft'], cmap='Reds', alpha=0.5, vmax=1.)\n",
    "# _ = ax.plot(xmesh, ymesh, '.b', markersize=1)\n",
    "ax.plot(xloc, yloc,'*k')\n",
    "cm = ax.pcolormesh(ds_short.x.values, ds_short.y.values, ds_short['Potential'], \n",
    "                   cmap='viridis', alpha=0.5, vmax=1.)\n",
    "# cm = ax.pcolormesh(ds_short.x.values, ds_short.y.values, ds_short['Potential'], \n",
    "#                    cmap='viridis', alpha=0.5, vmax=1.)\n",
    "# ax.set_xlim([ds_short.x.min(), ds_short.x.max()])\n",
    "# ax.set_ylim([ds_short.y.min(), ds_short.y.max()])\n",
    "swidth = 5\n",
    "xbounds = (xloc-swidth, xloc+swidth)\n",
    "ybounds = (yloc-swidth, yloc+swidth)\n",
    "mask = (ds.x<xbounds[1]) & (ds.x>xbounds[0]) & (ds.y>ybounds[0]) & (ds.y<ybounds[1]) \n",
    "ds_shorter = ds.where(mask, drop=True)\n",
    "xmesh, ymesh = np.meshgrid(ds_shorter.x, ds_shorter.y)\n",
    "_ = ax.plot(xmesh, ymesh, '.r', markersize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "#cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain', alpha=0.5)\n",
    "#cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraft'], cmap='Reds', alpha=0.5, vmax=1.)\n",
    "# _ = ax.plot(xmesh, ymesh, '.b', markersize=1)\n",
    "ax.plot(xloc, yloc,'*k')\n",
    "cm = ax.pcolormesh(ds_short.x.values, ds_short.y.values, ds_short['Potential'], \n",
    "                   cmap='viridis', alpha=0.5, vmax=1.)\n",
    "# cm = ax.pcolormesh(ds_short.x.values, ds_short.y.values, ds_short['Potential'], \n",
    "#                    cmap='viridis', alpha=0.5, vmax=1.)\n",
    "ax.set_xlim([ds_short.x.min(), ds_short.x.max()])\n",
    "ax.set_ylim([ds_short.y.min(), ds_short.y.max()])\n",
    "swidth = 2\n",
    "xbounds = (xloc-swidth, xloc+swidth)\n",
    "ybounds = (yloc-swidth, yloc+swidth)\n",
    "mask = (ds_short.x<xbounds[1]) & (ds_short.x>xbounds[0]) & (ds_short.y>ybounds[0]) & (ds_short.y<ybounds[1]) \n",
    "ds_shorter = ds_short.where(mask, drop=True)\n",
    "xmesh, ymesh = np.meshgrid(ds_shorter.x, ds_shorter.y)\n",
    "_ = ax.plot(xmesh, ymesh, '.r', markersize=2)\n",
    "#ds_shorter.Potential.sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_shorter.where(ds_shorter['Potential']==ds_shorter['Potential'].max(), drop=True).squeeze().x.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "#cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain', alpha=0.5)\n",
    "cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraft'], cmap='Reds', alpha=0.5, vmax=1.)\n",
    "# _ = ax.plot(xmesh, ymesh, '.b', markersize=1)\n",
    "ax.plot(*cur_position,'.r')\n",
    "#cm = ax.pcolormesh(ds_short.x.values, ds_short.y.values, ds_short['Potential'], cmap='viridis', alpha=0.5, vmax=10.)\n",
    "xbool = (ds_short.x < 32) & (ds_short.x > 26)\n",
    "ybool = (ds_short.y < 32) & (ds_short.y > 26)\n",
    "ds_new = ds_short['Potential'].where((xbool) & (ybool))\n",
    "cm = ax.pcolormesh(ds_new.x.values, ds_new.y.values, ds_new, cmap='viridis', alpha=0.5, vmax=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the relationship between look ahead potential fieldand movement dynamics\n",
    "x_idx = ds_new.argmin(dim=('x','y'))['x'].values\n",
    "y_idx = ds_new.argmin(dim=('x','y'))['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.degrees(np.arctan2(y_idx,x_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # forward cvm model\n",
    "        \n",
    "#         look_ahead_dist = 10.#cur_state['DriftHor']*mm.dt\n",
    "#         oro_center = ds['OroUpdraft'].sel(\n",
    "#             x=cur_state['PositionX'] + look_ahead_dist*np.sin(cur_state['DriftHeading']),\n",
    "#             y=cur_state['PositionY'] + look_ahead_dist*np.cos(cur_state['DriftHeading']),\n",
    "#             method='nearest'\n",
    "#         )\n",
    "#         oro_right = ds['OroUpdraft'].sel(\n",
    "#             x=cur_state['PositionX'] + look_ahead_dist*np.sin(cur_state['DriftHeading']+45*np.pi/180),\n",
    "#             y=cur_state['PositionY'] + look_ahead_dist*np.cos(cur_state['DriftHeading']+45*np.pi/180),\n",
    "#             method='nearest'\n",
    "#         )\n",
    "#         oro_left = ds['OroUpdraft'].sel(\n",
    "#             x=cur_state['PositionX'] + look_ahead_dist*np.sin(cur_state['DriftHeading']-45*np.pi/180),\n",
    "#             y=cur_state['PositionY'] + look_ahead_dist*np.cos(cur_state['DriftHeading']-45*np.pi/180),\n",
    "#             method='nearest'\n",
    "#         )\n",
    "#         new_state = deepcopy(cur_state)\n",
    "\n",
    "#       look_ahead_dist = 1.#cur_state['DriftHor']*mm.dt\n",
    "#         oro_center = ds['OroUpdraft'].sel(\n",
    "#             x=new_state['PositionX'] + look_ahead_dist*np.sin(new_state['DriftHeading']),\n",
    "#             y=new_state['PositionY'] + look_ahead_dist*np.cos(new_state['DriftHeading']),\n",
    "#             method='nearest'\n",
    "#         )\n",
    "#         oro_right = ds['OroUpdraft'].sel(\n",
    "#             x=new_state['PositionX'] + look_ahead_dist*np.sin(new_state['DriftHeading']+45*np.pi/180),\n",
    "#             y=new_state['PositionY'] + look_ahead_dist*np.cos(new_state['DriftHeading']+45*np.pi/180),\n",
    "#             method='nearest'\n",
    "#         )\n",
    "#         oro_left = ds['OroUpdraft'].sel(\n",
    "#             x=new_state['PositionX'] + look_ahead_dist*np.sin(new_state['DriftHeading']-45*np.pi/180),\n",
    "#             y=new_state['PositionY'] + look_ahead_dist*np.cos(new_state['DriftHeading']-45*np.pi/180),\n",
    "#             method='nearest'\n",
    "#         )\n",
    "# #         oro_grid = ds['OroUpdraft'].sel(\n",
    "# #             x=np.linspace(new_state['PositionX'] + look_ahead_dist*np.sin(new_state['DriftHeading']-45*np.pi/180),\n",
    "# #             y=new_state['PositionY'] + look_ahead_dist*np.cos(new_state['DriftHeading']-45*np.pi/180),\n",
    "# #             method='nearest'\n",
    "# #         )\n",
    "#         # select a 100 m at 10 m resolution grid in front of bird in the direction of movement and do SSRS \n",
    "#         oros = np.array([oro_center, oro_left, oro_right])\n",
    "#         angles = np.array([0, -45, 45])\n",
    "#         new_state['DriftHeading'] += angles[np.argmax(oros)]*np.pi/180\n",
    "#         new_state['DriftX'] = new_state['DriftHor']*np.sin(new_state['DriftHeading'])\n",
    "#         new_state['DriftY'] = new_state['DriftHor']*np.cos(new_state['DriftHeading'])\n",
    "#         #print(i, new_state['Omega'])\n",
    "        \n",
    "# #         new_state['DriftHor'] = np.sqrt(new_state['DriftX']**2 + new_state['DriftY']**2)\n",
    "#         new_state['DriftHeading'] = np.arctan2(new_state['DriftX'], new_state['DriftY'])\n",
    "#         oro_updraft = ds['OroUpdraft'].sel(\n",
    "#             x=cur_state['PositionX'],\n",
    "#             y=cur_state['PositionY'],\n",
    "#             method='nearest'\n",
    "#         )\n",
    "#         cur_elev = ds['GroundElevation'].sel(\n",
    "#             x=cur_state['PositionX'],\n",
    "#             y=cur_state['PositionY'],\n",
    "#             method='nearest'\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(OUT_DIR, 'fitted_regressors.pickle'), \"rb\") as f:\n",
    "    models = pickle.load(f)\n",
    "print(models.keys())\n",
    "valid_tracks = models['valid_tracks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option1\n",
    "dftrack = df[df['TrackID']==valid_tracks[20]]\n",
    "proj_bound = get_bound_from_positions(dftrack['PositionX'], dftrack['PositionY'])\n",
    "proj_bound = get_bound_from_width_and_southwest(\n",
    "    southwest_latlon=(-79.02, 38.36),\n",
    "    region_width_km = (40, 60),\n",
    "    resolution = 20.,\n",
    "    proj_crs = TELEMETRY_CRS\n",
    ")\n",
    "lonlat_bound = transform_bounds(proj_bound, TELEMETRY_CRS, GEO_CRS)\n",
    "ds = get_terrain_ds(\n",
    "    lonlat_bound = lonlat_bound,\n",
    "    wind_conditions = (10, 270),\n",
    "    resolution = 20.,\n",
    "    gf_sigma = 3.,\n",
    "    out_dir=os.path.join(TRACK_TERRAIN_DIR, 'pred')\n",
    ")\n",
    "ds = ds.where(\n",
    "    (ds.x >= proj_bound[0]) & (ds.y >= proj_bound[1]) &\n",
    "    (ds.x <= proj_bound[2]) & (ds.y <= proj_bound[3]),\n",
    "    drop=True\n",
    ")\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "cm = ax[0].pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain')\n",
    "cb = fig.colorbar(cm, ax=ax[0])\n",
    "ax[0].set_aspect('equal')\n",
    "cm = ax[1].pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraftS'], cmap='viridis', vmin=0, vmax=1.)\n",
    "cb = fig.colorbar(cm, ax=ax[1])\n",
    "ax[1].set_aspect('equal')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonlat_bound = transform_bounds(proj_bound, TELEMETRY_CRS, GEO_CRS)\n",
    "ds = get_terrain_ds(\n",
    "    lonlat_bound = lonlat_bound,\n",
    "    wind_conditions = (10, 270),\n",
    "    resolution = 20.,\n",
    "    gf_sigma = 3.,\n",
    "    out_dir=os.path.join(TRACK_TERRAIN_DIR, 'pred')\n",
    ")\n",
    "ds = ds.where(\n",
    "    (ds.x >= proj_bound[0]) & (ds.y >= proj_bound[1]) &\n",
    "    (ds.x <= proj_bound[2]) & (ds.y <= proj_bound[3]),\n",
    "    drop=True\n",
    ")\n",
    "#ds = ds.where(ds.x >= bounds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         swidth = 2\n",
    "#         xloc = cur_state['PositionX']\n",
    "#         yloc = cur_state['PositionY']\n",
    "#         xbounds = (xloc-swidth, xloc+swidth)\n",
    "#         ybounds = (yloc-swidth, yloc+swidth)\n",
    "#         mask = (ds_short.x<xbounds[1]) & (ds_short.x>xbounds[0]) & (ds_short.y>ybounds[0]) & (ds_short.y<ybounds[1]) \n",
    "#         ds_shorter = ds_short.where(mask, drop=True)\n",
    "        \n",
    "#         xbool = (ds_short.x < cur_state['PositionX'] + swidth) & (ds_short.x > 26)\n",
    "#         ybool = (ds_short.y < 32) & (ds_short.y > 26)\n",
    "#         ds_new = ds_short['Potential'].where((xbool) & (ybool))\n",
    "#         np.degrees(np.arctan2(y_idx,x_idx))\n",
    "#         ds_short.where\n",
    "#         ds_short = (('y', 'x'), potential)\n",
    "#         x_interp = [cur_state['PositionX']-0.1, cur_state['PositionX'], cur_state['PositionX']+0.1]\n",
    "#         y_interp = [cur_state['PositionY']-0.1, cur_state['PositionY'], cur_state['PositionY']+0.1]\n",
    "#         pot_interp = ds_short['Potential'].interp(x=x_interp, y=y_interp, method='linear')\n",
    "        \n",
    "        \n",
    "#         x_interp = [cur_state['PositionX']-0.1, cur_state['PositionX'], cur_state['PositionX']+0.1]\n",
    "#         y_interp = [cur_state['PositionY']-0.1, cur_state['PositionY'], cur_state['PositionY']+0.1]\n",
    "#         pot_interp = ds_short['Potential'].interp(x=x_interp, y=y_interp, method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = {\n",
    "            'PositionX': proj_bound[0] + 15000,\n",
    "            'PositionY': proj_bound[1] + 10000,\n",
    "            'VelocityX': 1.,  # dftrack['VelocityX_TU'].iloc[0],\n",
    "            'VelocityY': 1.,  # dftrack['VelocityY_TU'].iloc[0],\n",
    "            'DriftX': 0.,\n",
    "            'DriftY': 0.,\n",
    "            'PositionZ': 1000.,\n",
    "            'VelocityZ': 0.,\n",
    "            'DriftZ': 0.,\n",
    "            'Omega': 0.0,\n",
    "            'LogTauVer': 2.,\n",
    "            'LogTauHor': 2.\n",
    "        }\n",
    "list_of_simdfs = get_simulated_tracks(\n",
    "        start_state,\n",
    "        models,\n",
    "        ds,\n",
    "        num_tracks=36,\n",
    "        sim_time=20 * 60,\n",
    "        start_position_std=1.\n",
    ")\n",
    "# simdf = get_cvm_simulated_track(\n",
    "#                 start_state=start_state,\n",
    "#                 fitted_regressor=models['linreg'],\n",
    "#                 cvm_model=mm,\n",
    "#                 conditions_ds = ds,\n",
    "#                 sim_time_duration=100,\n",
    "#                 std_funcs=models['std_funcs'],\n",
    "#                 covariates=models['covariates']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax, ds = plot_track_on_terrain(dftrack, track_terrain_dir)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "#cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['GroundElevation'], cmap='terrain')\n",
    "cm = ax.pcolormesh(ds.x.values, ds.y.values, ds['OroUpdraftS'], cmap='viridis', vmin=0, vmax=1., alpha=0.5)\n",
    "cb = fig.colorbar(cm, ax=ax)\n",
    "ax.set_aspect('equal')\n",
    "for simdf in list_of_simdfs:\n",
    "    ax.plot(simdf['PositionX'], simdf['PositionY'], '-r', alpha=0.25, zorder=1000, linewidth=0.5)\n",
    "margin=100\n",
    "ax.set_xlim([simdf['PositionX'].min()-margin, simdf['PositionX'].max()+margin])\n",
    "ax.set_ylim([simdf['PositionY'].min()-margin, simdf['PositionY'].max()+margin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, ds = plot_track_on_terrain(dftrack, track_terrain_dir)\n",
    "# for simdf in list_of_simdfs:\n",
    "#     ax.plot(simdf['PositionX'], simdf['PositionY'], '-r', alpha=0.25, zorder=1000, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_pairs = {\n",
    "        'VelocityX': None,\n",
    "        # 'DriftX': 'WindSpeedU_10m',\n",
    "        'DriftX': None,\n",
    "        'VelocityY':  None,\n",
    "        'DriftY': None,\n",
    "        'PositionZ': None,\n",
    "        'VelocityZ': None,\n",
    "        'DriftZ': None,\n",
    "        'Omega': None,\n",
    "        'LogTauVer': None,\n",
    "        'LogTauHor': None,\n",
    "        'DriftHor':None,\n",
    "        'DriftHeading':None\n",
    "    }\n",
    "fig, ax = plot_cvm3d_state_history(plotting_pairs, None, None, list_of_simdfs, smoother=False, alpha=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Group']==b'pa','WindLateral'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_pairs = {\n",
    "        'VelocityX': 'VelocityX_TU',\n",
    "        # 'DriftX': 'WindSpeedU_10m',\n",
    "        'DriftX': None,\n",
    "        'VelocityY': 'VelocityY_TU',\n",
    "        'DriftY': None,\n",
    "        'PositionZ': 'Altitude',\n",
    "        'VelocityZ': 'VelocityVer_FD',\n",
    "        'DriftZ': None,\n",
    "        'Omega': None,\n",
    "        'LogTauVer': None,\n",
    "        'LogTauHor': None,\n",
    "    }\n",
    "fig, ax = plot_cvm3d_state_history(plotting_pairs, list_of_dfs[1], list_of_kfs[1], smoother=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictable = 'DriftX_next'\n",
    "covariates = ['DriftZ', 'Omega', 'OroT']\n",
    "Xmat = np.empty((len(covariates),obs_dict[predictable].size))\n",
    "for i, ivar in enumerate(covariates):\n",
    "    Xmat[i,:] = obs_dict[ivar]\n",
    "# X_poly_func = PolynomialFeatures(degree=1, include_bias=False, interaction_only=True)\n",
    "# X_std_scaler = StandardScaler()\n",
    "# X_scaler_func.fit_transform(X_poly_func.fit_transform(Xmat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_dict['DriftX_T'] =  (obs_dict['DriftX'] - np.mean(obs_dict['DriftX']))/np.std(obs_dict['DriftX'])\n",
    "# obs_dict['DriftY_T'] =  (obs_dict['DriftY'] - np.mean(obs_dict['DriftY']))/np.std(obs_dict['DriftY'])\n",
    "# obs_dict['DriftZ_T'] =  (obs_dict['DriftZ'] - np.mean(obs_dict['DriftZ']))/np.std(obs_dict['DriftZ'])\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "#ax.hist(obs_dict['DriftY'],bins=100,histtype='step',label='DriftZ', density=True)\n",
    "#ax.hist(obs_dict['Omega'],bins=100,histtype='step',label='Omega', density=True)\n",
    "ax.hist(obs_dict['OroT'],bins=100,histtype='step',label='OroT', density=True)\n",
    "#ax.hist(obs_dict['ThrT'],bins=100,histtype='step',label='ThrT', density=True)\n",
    "#ax.hist(obs_dict['AglT'],bins=100,histtype='step',label='AglT', density=True)\n",
    "#ax.set_xlim([-1,2])\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ivar in predictables:\n",
    "    obs_dict[f'{ivar}_next'] = obs_dict[ivar][1:]\n",
    "for ivar in covariates:\n",
    "    obs_dict[ivar] = obs_dict[ivar][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_simdfs = get_simulated_tracks_for_this_track(dftrack, models, num_tracks=36, start_position_std=200.)\n",
    "# #len(list_of_simdfs)\n",
    "# start_state=start_state\n",
    "# fitted_regressor=models['linreg']\n",
    "# cvm_model=mm\n",
    "# conditions_ds = ds\n",
    "# sim_time_duration=60*5\n",
    "# std_funcs=models['std_funcs']\n",
    "# covariates=models['covariates']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_cvm3d_state_history(list_of_dfs[20], list_of_kfs[20], smoother=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_kfs[0].get_mean('DriftZ').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_kfs[0].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_CVM3D_time_history(dftrack, None, smoother=False)\n",
    "#fig, ax, ds = plot_track_on_terrain(dftrack, track_terrain_dir, kf)\n",
    "#fig, ax = plot_CVM3DAugmented_time_history(dftrack, kf, smoother=False)\n",
    "fig, ax = plot_cvm3d_state_history(dftrack, kf, smoother=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"kf.pickle\", \"wb\") as f:\n",
    "    pickle.dump(kf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_dir = '/lustre/eaglefs/projects/car/rsandhu/csg_data/output/cvm_tracks'\n",
    "with open(os.path.join(track_dir, 'kf_5366.pickle'), 'rb') as outp:\n",
    "    cs = pickle.load(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_cvm3d_state_history(df[df['TrackID']==cs.id], cs, smoother=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation function\n",
    "x = np.linspace(-500,1000,1000)\n",
    "xd = np.linspace(-10,10,500)\n",
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "ax.plot(x, 1/np.exp(-(x-250)/100.))\n",
    "ax.grid(True)\n",
    "#plt.plot(xd, 1/(1+np.exp(-xd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation function\n",
    "x = np.linspace(0,100,1000)\n",
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "#ax.plot(x, 1/(1+np.exp(-(x-5)/1.)))\n",
    "ax.plot(x, np.log(x/(1-x)))\n",
    "ax.grid(True)\n",
    "#plt.plot(xd, 1/(1+np.exp(-xd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed()\n",
    "# predictables = list(fitted_regressor.keys())\n",
    "# states = cvm_model.state_names\n",
    "# cur_state = deepcopy(start_state)\n",
    "# cur_state['DriftHor'] = np.sqrt(cur_state['DriftX']**2 + cur_state['DriftY']**2)\n",
    "# cur_state['DriftHeading'] = np.arctan2(cur_state['DriftX'], cur_state['DriftY'])\n",
    "# cur_state['TimeElapsed'] = 0.\n",
    "# simdf = []\n",
    "# for _ in range(int(sim_time_duration)):\n",
    "#     # forward cvm model\n",
    "#     cur_state_list = [cur_state[iname] for iname in states]\n",
    "#     new_state_list = np.random.multivariate_normal(\n",
    "#         cvm_model.func_f(cur_state_list),\n",
    "#         cvm_model.func_Q(cur_state_list)\n",
    "#     )\n",
    "#     new_state = {k: new_state_list[i] for i, k in enumerate(states)}\n",
    "#     #print(new_state)\n",
    "#     # get covariates at the current step\n",
    "#     cur_covariates = {}\n",
    "# #     for k in covariates:\n",
    "# #         if k[:-1] in list(cur_state.keys()):\n",
    "# #             cur_covariates[k] = cur_state[k[:-1]]\n",
    "# #     for k, v in cur_covariates.items():\n",
    "# #         cur_covariates[k] = std_funcs[k].transform(np.atleast_2d(v))[0][0]\n",
    "#     # this is where agl and oro needs to be computed\n",
    "#     cur_covariates['OroS'] = conditions_ds['OroUpdraftS'].sel(x=cur_state['PositionX'], \n",
    "#                                                               y=cur_state['PositionY'], \n",
    "#                                                               method='nearest')\n",
    "#     cur_elev = conditions_ds['GroundElevation'].sel(x=cur_state['PositionX'], \n",
    "#                                                     y=cur_state['PositionY'], \n",
    "#                                                     method='nearest')\n",
    "#     cur_covariates['AglS'] = get_std_agl(cur_state['PositionZ'] - cur_elev)\n",
    "    \n",
    "#     for std_var in covariates:\n",
    "#         ivar = std_var.split('_')[0]\n",
    "#         ival = cur_covariates[ivar]\n",
    "#         cur_covariates[std_var] = std_funcs[std_var].transform(np.atleast_2d(ival))[0][0]\n",
    "        \n",
    "#     #print(cur_covariates)\n",
    "#     cur_covariates_list = [cur_covariates[k] for k in covariates]\n",
    "\n",
    "#     # pass it through fitted regressor to get new predictables\n",
    "#     cur_predictables = {k: np.nan for k in predictables}\n",
    "#     for iname in predictables:\n",
    "#         cur_predictables[iname] = np.random.normal(\n",
    "#             fitted_regressor[iname].predict(np.atleast_2d(cur_covariates_list))[0],\n",
    "#             0.001,\n",
    "#             1\n",
    "#         )\n",
    "#         cur_predictables[iname.split('_')[0]] = std_funcs[iname].inverse_transform(\n",
    "#             np.atleast_2d(cur_predictables[iname]))[0][0]\n",
    "#     #print(cur_predictables)\n",
    "# #     for istate in states:\n",
    "# #         change_var = f'{istate}Change'\n",
    "# #         if change_var in cur_predictables:\n",
    "# #             new_state[istate] += cur_predictables[change_var]\n",
    "#     new_state['DriftHor'] = cur_state['DriftHor'] + 0.0*cur_predictables['DriftHorChange']\n",
    "#     new_state['DriftHeading'] = cur_state['DriftHeading'] + 0.0 * cur_state['Omega']\n",
    "#     new_state['DriftX'] = new_state['DriftHor'] * np.sin(new_state['DriftHeading'])\n",
    "#     new_state['DriftY'] = new_state['DriftHor'] * np.cos(new_state['DriftHeading'])\n",
    "#     new_state['TimeElapsed'] = cur_state['TimeElapsed'] + cvm_model.dt\n",
    "#     cur_state = deepcopy(new_state)\n",
    "#     simdf.append(new_state)\n",
    "# simdf = pd.DataFrame(simdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation of directional potential, ways to make it fast:\n",
    "- Sparse solver linear system: Any way to make it faster?\n",
    "- Size/radius of orographic perception and resolution of terrain to solve in\n",
    "- not solving at each data point, can we annotate multiple points for each solve\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # change predictable variates\n",
    "#         ds_short = get_ds_short(cur_state['PositionX'], cur_state['PositionY'], deepcopy(ds), radius=100)\n",
    "#         #print(pot_interp, pot_interp.isel(x=0, y=0))\n",
    "#         pot_values = []\n",
    "#         for idist, iangle in look_ahead_conditions:\n",
    "#             this_point = [\n",
    "#                 cur_state['PositionX'] + np.cos(cur_state['DriftHeading']+np.radians(iangle))*idist,\n",
    "#                 cur_state['PositionY'] + np.sin(cur_state['DriftHeading']+np.radians(iangle))*idist,      \n",
    "#             ]\n",
    "#             pot_value = ds_short['Potential'].interp(x=this_point[0], y=this_point[1], method='linear').values\n",
    "#             pot_values.append(pot_value)\n",
    "#         #print(np.around(pot_values,4))\n",
    "#         move_probs = np.clip(np.array(pot_values), a_min=0.001, a_max=np.Inf)\n",
    "#         #move_probs = np.multiply(move_probs, look_ahead_scales)\n",
    "#         move_probs = np.power(move_probs, -1.0)\n",
    "#         move_probs /= np.sum(move_probs)\n",
    "#         #print(np.around(move_probs,2))\n",
    "#         idx_move = np.random.choice(range(len(move_probs)), p=move_probs)\n",
    "#         #idx_min = np.argmin(np.array(pot_values))\n",
    "#         _, chosen_angle = look_ahead_conditions[idx_move]\n",
    "#         #print(chosen_angle)\n",
    "#         cur_state['DriftHeading'] += np.random.normal(np.radians(chosen_angle), 10*np.pi/180)\n",
    "#         cur_state['DriftX'] = cur_state['DriftHor']*np.cos(cur_state['DriftHeading'])\n",
    "#         cur_state['DriftY'] = cur_state['DriftHor']*np.sin(cur_state['DriftHeading'])\n",
    "#         # add stochasticity to it\n",
    "#         points_list.append([point1_x, point1_y])\n",
    "        \n",
    "#         if ds_short['OroUpdraft'].max() > np.random.normal(0.75, 0.1, 1)[0]:\n",
    "#             #cur_state['DriftHor'] = np.random.normal(5, 1, 1)[0]#linear functions of potential around current point\n",
    "#             cur_state['DriftHeading'] = np.random.normal(90*np.pi/180, 1., 1)[0]\n",
    "#             cur_state['DriftX'] = cur_state['DriftHor']*np.cos(cur_state['DriftHeading'])\n",
    "#             cur_state['DriftY'] = cur_state['DriftHor']*np.sin(cur_state['DriftHeading'])\n",
    "#             #cur_state['LogTauHor'] = np.random.normal(-1, 1, 1)[0]\n",
    "#             #cur_state['Omega'] = np.random.normal(0, 0.01, 1)[0]\n",
    "#         else:\n",
    "#             cur_state['DriftHor'] = np.random.normal(2, 3, 1)[0]\n",
    "#             cur_state['DriftHeading'] = np.random.normal(0*np.pi/180, 1., 1)[0]\n",
    "#             cur_state['DriftX'] = cur_state['DriftHor']*np.cos(cur_state['DriftHeading'])\n",
    "#             cur_state['DriftY'] = cur_state['DriftHor']*np.sin(cur_state['DriftHeading'])\n",
    "#             #cur_state['LogTauHor'] =np.random.normal(-10, 1., 1)[0]\n",
    "#             #cur_state['Omega'] = np.random.normal(0, 1, 1)[0]\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs_env",
   "language": "python",
   "name": "rs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
