{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee114fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T22:13:52.408722Z",
     "iopub.status.busy": "2022-08-23T22:13:52.408424Z",
     "iopub.status.idle": "2022-08-23T22:13:54.422586Z",
     "shell.execute_reply": "2022-08-23T22:13:54.422848Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathos.multiprocessing as mp\n",
    "import xarray as xr\n",
    "#from telemetry_module import *\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import time\n",
    "from statsmodels.graphics import tsaplots\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit, expit\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer, RobustScaler\n",
    "from sklearn.linear_model import ARDRegression, LinearRegression, BayesianRidge, Lasso\n",
    "from sklearn.linear_model import LassoCV, Ridge, RidgeCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesfilt.telemetry.utils import *\n",
    "from bayesfilt.telemetry.utils import get_bound_from_positions, plot_relation\n",
    "from simulate_tracks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cddb0ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T22:14:30.590665Z",
     "iopub.status.busy": "2022-08-23T22:14:30.590358Z",
     "iopub.status.idle": "2022-08-23T22:14:32.672979Z",
     "shell.execute_reply": "2022-08-23T22:14:32.673291Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = get_annotated_telemetry_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = os.path.join(telemetry_dir, 'csg_ge_vr.prq_tracks_ca_annotated_calibrated')\n",
    "# df.to_parquet(fpath)\n",
    "# df[['Heading','HeadingRate','HeadingRateRaw']].iloc[1100:1100+17]\n",
    "df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute lagged, next and change version of predictable vars\n",
    "#df['AglMod'] = expit(df['AltitudeAgl']/25. - 4.)\n",
    "#df['HeadingRateChange'] = df['HeadingRate'].diff()\n",
    "#df['HeadingRate'] = df['HeadingRateRaw'].rolling(3, min_periods=1, center=True).mean().bfill().ffill()\n",
    "#df['HrateByHspeed'] = df['HeadingRate'].divide(df['VelocityHor'].clip(lower=0.5, upper=np.inf))\n",
    "#varnames = ['VelocityHor', 'HeadingRate', 'HeadingRateAbs', 'VelocityVer']\n",
    "time_lags = [5, 10, 30, 60, 120]\n",
    "variables = {}\n",
    "variables['Pred'] = ['VelocityHor', 'HeadingRate', 'VelocityVer']\n",
    "#variables['Pred'] = ['VelocityHor', 'HrateByHspeed', 'VelocityVer']\n",
    "#variables['PredChange'] = [f'{ix}Change' for ix in variables['Pred']]\n",
    "variables['PredNext'] = [f'{ix}Next' for ix in variables['Pred']]\n",
    "for i, ivar in enumerate(variables['Pred']):\n",
    "    #df[variables['PredChange'][i]] = df[ivar].diff(-1).ffill().bfill()\n",
    "    df[variables['PredNext'][i]] = df[ivar].shift(-1).ffill().bfill()\n",
    "for ilag in time_lags:\n",
    "    variables[f'PredLag{ilag}'] = [f'{ix}Lag{ilag}' for ix in variables['Pred']]\n",
    "    for ix, iy in zip(variables[f'PredLag{ilag}'], variables['Pred']):\n",
    "        df[ix] = df[iy].shift(ilag).ffill().bfill()\n",
    "        #df[ix] = df[iy].diff(ilag).ffill().bfill()\n",
    "        # df[ix] = df[iy] - df[iy].shift(ilag).ffill().bfill()\n",
    "        #df[ix] = df[iy].shift(ilag).ffill().bfill()\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ix for ix in df.columns if 'Oro' in ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dist_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8aef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize all the variables \n",
    "std_choice = 'robust'\n",
    "if std_choice == 'robust':\n",
    "    std_transformer = RobustScaler(unit_variance=True, quantile_range=(5.0, 95.0))\n",
    "elif std_choice == 'quantile':\n",
    "    std_transformer = QuantileTransformer(output_distribution='normal')\n",
    "elif std_choice == 'standard':\n",
    "    std_transformer = StandardScaler()\n",
    "else:\n",
    "    print('invalid std choice')\n",
    "# dfshort['OroSmoothNearLeftDiff'] = np.maximum.reduce([\n",
    "#     dfshort['OroSmoothNearL15Diff'],\n",
    "#     dfshort['OroSmoothNearL30Diff'],\n",
    "#     dfshort['OroSmoothNearL60Diff']\n",
    "# ])\n",
    "# dfshort['OroSmoothNearRightDiff'] = np.maximum.reduce([\n",
    "#     dfshort['OroSmoothNearR15Diff'],\n",
    "#     dfshort['OroSmoothNearR30Diff'],\n",
    "#     dfshort['OroSmoothNearR60Diff']\n",
    "# ])\n",
    "variables['Env'] = [\n",
    "    'Agl', 'OroSmooth', 'HeadingRateAbs',\n",
    "    'WindSpeed80m',  'WindSupport80m',  'WindLateral80m', 'WindLateral80mAbs',\n",
    "    #'OroSmoothNearLeftDiff', 'OroSmoothNearRightDiff',\n",
    "    \n",
    "    'ElevFiftyDiff', 'ElevOnehdDiff', 'ElevTwohdDiff', 'ElevFvehdDiff', 'ElevOnekmDiff',\n",
    "    'OroSmoothFiftyDiff', 'OroSmoothOnehdDiff', 'OroSmoothTwohdDiff', 'OroSmoothFvehdDiff', 'OroSmoothOnekmDiff',\n",
    "    \n",
    "    'OroSmoothFiftyL15Diff', 'OroSmoothFiftyR15Diff',\n",
    "    'OroSmoothFiftyL30Diff', 'OroSmoothFiftyR30Diff',\n",
    "    'OroSmoothFiftyL60Diff', 'OroSmoothFiftyR60Diff',\n",
    "    \n",
    "    'OroSmoothOnehdL15Diff', 'OroSmoothOnehdR15Diff', \n",
    "    'OroSmoothOnehdL30Diff', 'OroSmoothOnehdR30Diff', \n",
    "    'OroSmoothOnehdL60Diff', 'OroSmoothOnehdR60Diff',\n",
    "    \n",
    "    'OroSmoothTwohdL15Diff', 'OroSmoothTwohdR15Diff', \n",
    "    'OroSmoothTwohdL30Diff', 'OroSmoothTwohdR30Diff', \n",
    "    'OroSmoothTwohdL60Diff', 'OroSmoothTwohdR60Diff',\n",
    "]\n",
    "idict = {ix:iy for ix,iy in variables.items() if 'Std' not in ix}\n",
    "std_funcs = {}\n",
    "for key, varlist in idict.items():\n",
    "    print(key,': ', *varlist)\n",
    "    variables[f'{key}Std'] = [f'{ix}Std' for ix in varlist]\n",
    "    for ix, iy in zip(variables[f'{key}Std'], varlist):\n",
    "        dfshort[ix] =  std_transformer.fit_transform(np.atleast_2d(dfshort[iy].values).T)\n",
    "        std_funcs[ix] = deepcopy(std_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aeb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = f'fit_ca.pickle_{std_choice}'\n",
    "with open(os.path.join(OUT_DIR, f'{model_str}_df'), \"wb\") as f:\n",
    "    pickle.dump(dfshort, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,2.5))\n",
    "# #dfshort['GroundSlope'].hist(bins=100, ax=ax, histtype='step')\n",
    "# rnge = (-300,1000)\n",
    "# dfshort['WindLateral80m'].hist(bins=100, ax=ax, histtype='step')\n",
    "# dfshort['WindSupport80m'].hist(bins=100, ax=ax, histtype='step')\n",
    "#dfshort['WindLateral80mMod'].hist(bins=100, ax=ax, histtype='step')\n",
    "# #dfshort['HeadingRateNextStdLinRegRes'].hist(bins=100, ax=ax, histtype='step')\n",
    "# for icase in cases:\n",
    "#     #dfshort[f'Elev{icase}Diff'].hist(bins=100, ax=ax, histtype='step')\n",
    "#     #dfshort[f'OroSmooth{icase}'].hist(bins=100, ax=ax, histtype='step')\n",
    "#     dfshort[f'OroSmooth{icase}Diff'].hist(bins=100, ax=ax, histtype='step')\n",
    "#dfshort['OroSmoothNearDiff'].hist(bins=100, ax=ax, histtype='step')\n",
    "#dfshort['OroSmoothNearL30DiffStd'].hist(bins=100, ax=ax, histtype='step')\n",
    "#dfshort['OroSmoothNearR30DiffStd'].hist(bins=100, ax=ax, histtype='step')\n",
    "# dfshort['OroSmoothCloseL30DiffStd'].hist(bins=100, ax=ax, histtype='step')\n",
    "# dfshort['OroSmoothCloseR30DiffStd'].hist(bins=100, ax=ax, histtype='step')\n",
    "# dfshort['OroSmoothMidDiff'].hist(bins=100, ax=ax, histtype='step')\n",
    "# dfshort['OroSmoothFarDiff'].hist(bins=100, ax=ax, histtype='step')\n",
    "#dfshort['OroSmoothFartherDiff'].hist(bins=100, ax=ax, histtype='step',range=rnge)\n",
    "#dfshort['WindSpeed80m'].hist(bins=100, ax=ax, histtype='step')\n",
    "#dfshort['WindDirection80m'].hist(bins=100, ax=ax, histtype='step')\n",
    "#dfshort['WindRelativeAngle80m'].hist(bins=100, ax=ax, histtype='step')\n",
    "# dfshort['VelocityVerStd'].hist(bins=100, ax=ax, histtype='step', color='b')\n",
    "# dfshort['VelocityVer'].hist(bins=100, ax=ax, histtype='step', color='b')\n",
    "#dfshort['TrackTimeElapsed'].hist(bins=100, ax=ax, histtype='step', color='b', range=(0,100))\n",
    "# #dfshort['VelocityHor'].hist(bins=100, ax=ax, histtype='step', color='b')\n",
    "varname = 'VelocityVer'#'HrateByHspeed'\n",
    "for ilag in time_lags:\n",
    "    dfshort[f'{varname}Lag{ilag}'].hist(bins=100, ax=ax, histtype='step', color='r')\n",
    "# dfshort[f'{varname}Next'].hist(bins=100, ax=ax, histtype='step', color='b')\n",
    "#dfshort['HeadingRate30ago'].hist(bins=100, ax=ax, histtype='step', color='r', range=(-10,10))\n",
    "# dfshort['WindSupport80m'].hist(bins=100, ax=ax, histtype='step')\n",
    "# dfshort['WindLateral80mAbs'].hist(bins=100, ax=ax, histtype='step')\n",
    "# dfshort['WindLateral80m'].hist(bins=100, ax=ax, histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481416f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = {}\n",
    "model_structure.clear()\n",
    "for ix in variables['PredNextStd']:\n",
    "    model_structure[ix] = deepcopy(variables['EnvStd'])\n",
    "# dfshort['AglStdFifth'] = dfshort['AglStd'].pow(5)\n",
    "# dfshort['AglStdCubic'] = dfshort['AglStd'].pow(3)\n",
    "model_structure['VelocityHorNextStd'] = [\n",
    "    'AglStd', #'AglNearStd', 'AglMidStd', 'AglFarStd',\n",
    "    'ElevFiftyDiffStd', 'ElevOnehdDiffStd', 'ElevTwohdDiffStd', 'ElevFvehdDiffStd', 'ElevOnekmDiffStd',\n",
    "    'OroSmoothStd',  'WindSupport80mStd', #'WindLateral80mStd', \n",
    "    'OroSmoothFiftyDiffStd','OroSmoothCloseDiffStd', #'OroSmoothMidDiffStd', 'OroSmoothFarDiffStd', 'OroSmoothFartherDiffStd',\n",
    "    'VelocityVerStd',  \n",
    "    #'VelocityVerLag10Std', \n",
    "    #'VelocityVerLag30Std', 'VelocityVerLag60Std', 'VelocityVerLag120Std',\n",
    "    'HeadingRateAbsStd', \n",
    "    #'HeadingRateLag10Std', 'HeadingRateLag30Std',  'HeadingRateLag60Std', 'HeadingRateLag120Std', \n",
    "    #'VelocityHorLag10Std', \n",
    "    'VelocityHorLag30Std', #'VelocityHorLag60Std',  'VelocityHorLag120Std'\n",
    "]\n",
    "model_structure['VelocityVerNextStd'] = [\n",
    "    'AglStd', #'AglStdCubic', 'AglStdFifth', #'AglNearStd', 'AglMidStd', 'AglFarStd',\n",
    "    'ElevNearDiffStd', #'ElevCloseDiffStd', 'ElevMidDiffStd', 'ElevFarDiffStd', 'ElevFartherDiffStd',\n",
    "    'OroSmoothStd',  'WindSupport80mStd', 'WindLateral80mAbsStd', #'WindLateral80mStd',\n",
    "    'OroSmoothNearDiffStd', #'OroSmoothCloseDiffStd', #'OroSmoothMidDiffStd', 'OroSmoothFarDiffStd','OroSmoothFartherDiffStd',\n",
    "    'VelocityHorStd', \n",
    "    #'VelocityHorLag10Std', \n",
    "    #'VelocityHorLag30Std','VelocityHorLag60Std',#'VelocityHorLag120Std',\n",
    "    'HeadingRateAbsStd', \n",
    "    #'HeadingRateLag10Std','HeadingRateLag30Std', 'HeadingRateLag60Std','HeadingRateLag120Std',\n",
    "    #'VelocityVerLag10Std', \n",
    "    'VelocityVerLag30Std','VelocityVerLag120Std',\n",
    "]\n",
    "model_structure['HeadingRateNextStd'] = [\n",
    "    #'AglStd',\n",
    "    'OroSmoothNearLeftDiffStd', 'OroSmoothNearRightDiffStd',\n",
    "#     'OroSmoothNearL15DiffStd', 'OroSmoothNearR15DiffStd',\n",
    "#     'OroSmoothNearL30DiffStd', 'OroSmoothNearR30DiffStd',\n",
    "#     'OroSmoothNearL60DiffStd', 'OroSmoothNearR60DiffStd',\n",
    "#     'OroSmoothCloseL15DiffStd', 'OroSmoothCloseR15DiffStd',\n",
    "#     'OroSmoothCloseL30DiffStd', 'OroSmoothCloseR30DiffStd',\n",
    "#     'OroSmoothCloseL60DiffStd', 'OroSmoothCloseR60DiffStd',\n",
    "    #'ElevNearDiffStd', 'ElevCloseDiffStd', 'ElevMidDiffStd', 'ElevFarDiffStd',\n",
    "    #'WindLateral80mStd', #'WindSupport80mStd',\n",
    "    #'OroSmoothStd',\n",
    "    #'VelocityHorStd', #'VelocityHorLag5Std','VelocityHorLag10Std', 'VelocityHorLag20Std',\n",
    "    #'VelocityVerStd', #'VelocityVerLag5Std', 'VelocityVerLag10Std', 'VelocityVerLag20Std',\n",
    "    'HeadingRateLag5Std', 'HeadingRateLag10Std', #'HeadingRateLag30Std', #'HeadingRateLag60Std', #'HeadingRateLag120Std' \n",
    "]\n",
    "# model_structure['HrateByHspeedNextStd'] = [\n",
    "#     'OroSmoothNearL30DiffStd', 'OroSmoothNearR30DiffStd',\n",
    "#     'OroSmoothCloseL30DiffStd', 'OroSmoothCloseR30DiffStd',\n",
    "#     #'ElevNearDiffStd', 'ElevMidDiffStd', 'ElevFarDiffStd',\n",
    "#     'WindLateral80mAbsStd', #'WindSupport80mStd',\n",
    "#     'VelocityVerStd', #'VelocityHorStd', 'OroSmoothStd',\n",
    "#     #'VelocityHorStd', #'VelocityHorLag5Std','VelocityHorLag10Std', 'VelocityHorLag20Std',\n",
    "#     #'VelocityVerStd', 'VelocityVerLag5Std', 'VelocityVerLag10Std', 'VelocityVerLag20Std',\n",
    "#     #'HrateByHspeedLag5Std', \n",
    "#     #'HrateByHspeedLag10Std', 'HrateByHspeedLag30Std',#'HeadingRateLag60Std', #'HeadingRateLag120Std' \n",
    "#]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab4ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = {\n",
    "    #'lasso': LassoCV(fit_intercept=True, cv=4, selection='random', n_alphas=100, eps=1e-2,\n",
    "    #                 tol=1e-3, n_jobs=4, verbose=False, max_iter=20000),\n",
    "    #'Ard': ARDRegression(compute_score=True, fit_intercept=True, n_iter=400, tol=1e-2, verbose=False),\n",
    "    'LinReg': LinearRegression(fit_intercept=True, n_jobs=8, copy_X=True)\n",
    "}\n",
    "poly_func_dict = {\n",
    "    'VelocityHorNextStd': PolynomialFeatures(degree=3, include_bias=False, interaction_only=True),\n",
    "    'VelocityVerNextStd': PolynomialFeatures(degree=3, include_bias=False, interaction_only=True),\n",
    "    'HeadingRateNextStd': PolynomialFeatures(degree=7, include_bias=False, interaction_only=False),\n",
    "}\n",
    "poly_func_dict = {\n",
    "    'VelocityHorNextStd': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False),\n",
    "    'VelocityVerNextStd': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False),\n",
    "    'HeadingRateNextStd': PolynomialFeatures(degree=7, include_bias=False, interaction_only=False),\n",
    "    #'HrateByHspeedNextStd': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False),\n",
    "}\n",
    "poly_func_error_dict = {\n",
    "    'VelocityHorNextStd': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False),\n",
    "    'VelocityVerNextStd': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False),\n",
    "    'HeadingRateNextStd': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False),\n",
    "    #'HrateByHspeedNextStd': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False),\n",
    "}\n",
    "models = {}\n",
    "models.clear()\n",
    "for pred_var, covariates in model_structure.items():\n",
    "    poly_funcs = poly_func_dict[pred_var]\n",
    "    X_features = poly_funcs.fit_transform(dfshort.loc[:, covariates].values)\n",
    "    poly_funcs.feature_names_in_ = covariates\n",
    "    model = {}\n",
    "    model['Covariates'] = covariates\n",
    "    model['Features'] = poly_funcs\n",
    "    result_df = pd.DataFrame(index=list(poly_funcs.get_feature_names_out()) + ['Bias', 'Score'])\n",
    "    for reg_name, regressor in regressors.items():\n",
    "        \n",
    "        # mean modeling\n",
    "        Yvec = dfshort.loc[:, pred_var].values\n",
    "        start_time = time.time()\n",
    "        fitted_model = regressor.fit(X_features, Yvec)\n",
    "        dfshort[f'{pred_var}{reg_name}'] = fitted_model.predict(X_features)\n",
    "        model[reg_name] = deepcopy(fitted_model)\n",
    "        score = np.around(fitted_model.score(X_features, Yvec),3)\n",
    "        coeff_val = np.around(fitted_model.coef_[:], 5)\n",
    "        result_df[f'{pred_var}{reg_name}'] = list(coeff_val) + [fitted_model.intercept_, score]\n",
    "        # error modeling\n",
    "        \n",
    "        \n",
    "        res_vec = Yvec - fitted_model.predict(X_features)\n",
    "        dfshort[f'{pred_var}{reg_name}Res'] = res_vec\n",
    "        res_vec = (Yvec - fitted_model.predict(X_features))**2\n",
    "        #res_vec = np.abs(Yvec - fitted_model.predict(X_features))\n",
    "        dfshort[f'{pred_var}{reg_name}Error'] = res_vec\n",
    "        poly_funcs_error = poly_func_error_dict[pred_var]\n",
    "        X_features_error = poly_funcs_error.fit_transform(dfshort.loc[:, covariates].values)\n",
    "        poly_funcs_error.feature_names_in_ = covariates\n",
    "        model['FeaturesError'] = poly_funcs_error\n",
    "        fitted_error_model = regressor.fit(X_features_error, res_vec)\n",
    "        model[f'{reg_name}Error'] = deepcopy(fitted_error_model)\n",
    "        dfshort[f'{pred_var}{reg_name}ErrorPred']  = fitted_error_model.predict(X_features_error)\n",
    "        score_err = np.around(fitted_error_model.score(X_features_error, res_vec), 3)\n",
    "        #result_df[f'{pred_var}{reg_name}Error'] = list(coeff_val) + [fitted_error_model.intercept_, score_err]\n",
    "        \n",
    "        #end\n",
    "        run_time = np.around(((time.time() - start_time)) / 60., 2)\n",
    "        print(f'{reg_name}-{pred_var}-{score}-{score_err}-took {run_time} mins', flush=True)\n",
    "    model['df'] = pd.DataFrame(result_df)\n",
    "    models[pred_var] = model\n",
    "models = pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00006419",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_vars =  ['VelocityVerNextStd','VelocityHorNextStd','HeadingRateNextStd']\n",
    "#pred_vars = ['VelocityVerNextStd','VelocityHorNextStd','HrateByHspeedNextStd']\n",
    "ylim = None\n",
    "for pred in pred_vars:\n",
    "    print(pred)\n",
    "    fig, ax = plot_relation(dfshort, pred, model_structure[pred],  quant=0.95, clr='b', \n",
    "                            lags=True, ylim=ylim)\n",
    "    _,_ = plot_relation(dfshort, f'{pred}LinReg', model_structure[pred],  quant=0.95, \n",
    "                        clr='r', fig=fig, ax=ax, lags=True, ylim=ylim)\n",
    "    legend_elements = [Line2D([0], [0], color='r', ls='-',lw=2, label='Calibrated model'),\n",
    "                       Line2D([0], [0], color='b', ls='-', lw=2, label='Data')]\n",
    "    ax[-1].legend(handles=legend_elements, loc='upper left',)\n",
    "    #plt.savefig(os.path.join(fig_dir, f'{pred}.png'))\n",
    "#  title='Mean of conditional disribution'\n",
    "#plt.legend(handles=[red_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cd1fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pred in pred_vars:\n",
    "    print(pred)\n",
    "    fig, ax = plot_relation(dfshort, f'{pred}LinRegError', model_structure[pred],  quant=0.95, \n",
    "                            clr='b', lags=True, ylim=None)\n",
    "    _,_ = plot_relation(dfshort, f'{pred}LinRegErrorPred', model_structure[pred],  quant=0.95, \n",
    "                        clr='r', fig=fig, ax=ax, lags=True, ylim=None)\n",
    "    legend_elements = [Line2D([0], [0], color='r', ls='-',lw=2, label='Calibrated model'),\n",
    "                       Line2D([0], [0], color='b', ls='-', lw=2, label='Data')]\n",
    "    ax[-1].legend(handles=legend_elements, loc='upper left',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = f'fit_ca.pickle_{std_choice}'\n",
    "with open(os.path.join(OUT_DIR, f'{model_str}_model'), \"wb\") as f:\n",
    "    pickle.dump(models, f)\n",
    "with open(os.path.join(OUT_DIR, f'{model_str}_funcs'), \"wb\") as f:\n",
    "    pickle.dump(std_funcs, f)\n",
    "with open(os.path.join(OUT_DIR, f'{model_str}_df'), \"wb\") as f:\n",
    "    pickle.dump(dfshort, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51837cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_funcs['OroSmoothStd'].inverse_transform(np.atleast_2d([0.6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcd730",
   "metadata": {},
   "source": [
    "### JUnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25484dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ivar in model_structure[pred]:\n",
    "#     #ivar = ivar.split('Std')[0]\n",
    "#     #pred = pred.split('Std')[0]\n",
    "#     fig, ax = plot_2drelation(dfshort, ivar, pred, quant=0.95, nsamples=100000, scatter=False, clr='b')\n",
    "#     plot_2drelation(dfshort, ivar, f'{pred}LinReg', quant=0.95, nsamples=100000, fig=fig, ax=ax,clr='r')\n",
    "#     print(pred, ivar, dfshort[pred].corr(dfshort[ivar]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classify flight modes\n",
    "# rolling_time = 20.\n",
    "# vspeed_roll = df['SpeedVer'].rolling(int(rolling_time), center=True).mean().bfill().ffill()\n",
    "# headingrate_roll = df['HeadingRateHor'].abs().rolling(int(rolling_time), center=True).mean().bfill().ffill()\n",
    "# vspeed_classifier = {'Gliding': (-1000, -1), 'Oro_soaring':(-1,1000.), 'Thermal_soaring': (1.,1000.)}\n",
    "# hrate_classifier = {'Gliding': (0, 5), 'Oro_soaring':(0, 5.), 'Thermal_soaring': (6.,1000)}\n",
    "# df['FlightMode'] = 'U'\n",
    "# for key, val in vspeed_classifier.items():\n",
    "#     #print(key, val, hrate_classifier[key])\n",
    "#     ibool = (vspeed_roll.between(*val)) & (headingrate_roll.between(*hrate_classifier[key]))\n",
    "#     df.loc[ibool, 'FlightMode'] =  key[0].upper()\n",
    "#     print(key, ' : ', np.around(ibool.sum()*100/df.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47afc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AglMode'] = 'U'\n",
    "agl_classifier = {'Low_agl': (-1000, 250), 'high_agl':(250,100000.), }\n",
    "for key, val in agl_classifier.items():\n",
    "    #print(key, val, hrate_classifier[key])\n",
    "    ibool = df['AltitudeAGL'].between(*val)\n",
    "    df.loc[ibool, 'AglMode'] =  key[0].upper()\n",
    "    print(key, ' : ', np.around(ibool.sum()*100/df.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfcbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictables\n",
    "df['HeadingRateHorAbs'] = df['HeadingRateHor'].abs()\n",
    "Y_colnames = ['AccnVer', 'AccnHorTangential', 'HeadingRateHorAbs']\n",
    "Y_varnames = [f'{icol}_Next' for icol in Y_colnames] \n",
    "for icol, ivar in zip(Y_colnames, Y_varnames):\n",
    "    df[ivar] = df.groupby('TrackID')[icol].shift(-1).ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e25815",
   "metadata": {},
   "source": [
    "## Model calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d2b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_varnames = []\n",
    "X_varnames +=  ['AltitudeAGL', 'AltitudeAGL_5ago',  'AltitudeAGL_10ago']\n",
    "X_varnames += ['SpeedVer', 'SpeedVer_5ago', 'SpeedVer_10ago']\n",
    "X_varnames += ['SpeedHor', 'SpeedHor_5ago', 'SpeedHor_10ago']\n",
    "X_varnames += ['HeadingRateHorAbs', 'HeadingRateHorAbs_5ago', 'HeadingRateHorAbs_10ago']\n",
    "X_varnames += ['DeardoffSpeed']\n",
    "X_varnames += ['OrographicUpdraft']\n",
    "X_varnames += ['OrographicUpdraft_10m_0Deg', 'OrographicUpdraft_10m_0Deg']\n",
    "X_varnames += ['OrographicUpdraft_20m_0Deg', 'OrographicUpdraft_20m_0Deg']\n",
    "X_varnames += ['OrographicUpdraft_30m_0Deg', 'OrographicUpdraft_30m_0Deg']\n",
    "X_varnames += ['OrographicUpdraft_40m_0Deg', 'OrographicUpdraft_40m_0Deg']\n",
    "X_varnames += ['OrographicUpdraft_50m_0Deg', 'OrographicUpdraft_50m_0Deg']\n",
    "X_varnames += ['OrographicUpdraft_100m_0Deg', 'OrographicUpdraft_100m_0Deg']\n",
    "X_varnames += ['WindSpeed_80m']\n",
    "#X_varnames += ['SurfaceRoughness', 'TotalCloudCover']\n",
    "#X_varnames += ['GroundSlope', 'GroundAspect']\n",
    "X_varnames = list(set(X_varnames))\n",
    "len(X_varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_func = PolynomialFeatures(degree=1, include_bias=False, interaction_only=True)\n",
    "X_scaler_func = PowerTransformer(method='box-cox', standardize=True) \n",
    "X_scaler_func = QuantileTransformer(output_distribution='normal') #StandardScaler()\n",
    "Y_scaler_func = QuantileTransformer(output_distribution='normal') #StandardScaler()\n",
    "regressor1 = LassoCV(fit_intercept=False, cv=10, selection='random', n_alphas=100, eps=1e-2, \n",
    "                     tol=1e-3, n_jobs=4, verbose=False, max_iter=20000)\n",
    "regressor2 = ARDRegression(compute_score=True, fit_intercept=False, n_iter=400, tol=1e-2, verbose=False)\n",
    "regressor3 = LinearRegression(fit_intercept=False, n_jobs=4, copy_X=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029bb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = b'pa'\n",
    "num_samples = 100000\n",
    "min_oro = 1e-8\n",
    "ibool = (df['Group']==b'wy') & (df[new_colname].notna()) & (df['OrographicUpdraft']> min_oro) \n",
    "for icol in [ix for ix in X_varnames if 'Updraft_' in ix]:\n",
    "    ibool = ibool & (df[icol]> min_oro)\n",
    "results = {}\n",
    "models = {}\n",
    "for i, regressor in enumerate([regressor1, regressor2, regressor3]):\n",
    "    result_dfs = {}\n",
    "    for flight_mode in ['L', 'H']:\n",
    "        print(flight_mode, end=\"::\")\n",
    "        #this_case = (newdf['FlightMode'] == flight_mode) & (newdf['Group'] == group_id)\n",
    "        this_case = ibool & (df['AglMode'] == flight_mode)\n",
    "        dfshort = df.loc[this_case, X_varnames+Y_varnames].sample(n=num_samples, axis=0)\n",
    "        Xmat = dfshort.loc[:, X_varnames].values\n",
    "        Xmat_to_fit = X_scaler_func.fit_transform(X_poly_func.fit_transform(Xmat))\n",
    "        #print(Xmat.shape, Xmat_to_fit.shape)\n",
    "        result_df = pd.DataFrame({'Varname':X_varnames})\n",
    "        for predictable in Y_varnames:\n",
    "            print(predictable, end='-')\n",
    "            Yvec = dfshort.loc[:, predictable].values\n",
    "            Yvec_to_fit = Y_scaler_func.fit_transform(np.atleast_2d(Yvec).T).reshape(-1)\n",
    "            fitted_model = regressor.fit(Xmat_to_fit, Yvec_to_fit)\n",
    "            models[(i, flight_mode)] = fitted_model\n",
    "            result_df[f'Coeff_{predictable}'] = np.around(fitted_model.coef_[:], 10)\n",
    "        result_dfs[flight_mode] = result_df\n",
    "    results[i] = result_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, result_dfs in results.items():\n",
    "    for _, result_df in result_dfs.items():\n",
    "        for predictable in Y_varnames:\n",
    "            col_name = f'Coeff_{predictable}'\n",
    "            result_df.loc[result_df[col_name].abs() < 1e-3, col_name] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20345626",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e55165",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "ibool = (df['Group']==b'wy')\n",
    "icol = Y_varnames[0]\n",
    "idata = df.loc[ibool,icol].sample(10000).values.reshape(-1,1)\n",
    "X_scaler_func = StandardScaler(with_mean=True)\n",
    "X_scaler_func = QuantileTransformer(output_distribution='normal')\n",
    "#X_scaler_func = PowerTransformer(method='box-cox', standardize=True)\n",
    "idata = X_scaler_func.fit_transform(idata)\n",
    "_=ax.hist(idata, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "ibool = (df['Group']==b'wy') & (df['OrographicUpdraft_100m_45Deg']> 1e-8)\n",
    "idata = df.loc[ibool, 'OrographicUpdraft_100m_45Deg'].sample(10000).values.reshape(-1,1)\n",
    "#X_scaler_func = StandardScaler(with_mean=False)\n",
    "X_scaler_func = QuantileTransformer(output_distribution='normal')\n",
    "#X_scaler_func = PowerTransformer(method='box-cox', standardize=True)\n",
    "idata = X_scaler_func.fit_transform(idata)\n",
    "_=ax.hist(idata, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_angle(xdiff):\n",
    "    xdiff = xdiff % (2. * np.pi)\n",
    "    if xdiff > np.pi:\n",
    "        xdiff -= 2. * np.pi\n",
    "    return xdiff\n",
    "def forward_move(zcur, zdelta, dt, tfac, Xdrift, Ydrift ):\n",
    "    znew = deepcopy(zcur)\n",
    "    \n",
    "    znew['AccnVer'] = zdelta['AccnVer_Next'] \n",
    "    #znew['Vaccn'] = accn_fac*znew['Vaccn'] if abs(znew['Vaccn']) > 0.75 else znew['Vaccn']\n",
    "    \n",
    "    znew['AccnHor'] = zdelta['AccnHorTangential_Next']\n",
    "    #znew['Haccn'] = accn_fac*znew['Haccn'] if abs(znew['Haccn']) > 6. else znew['Haccn']\n",
    "    \n",
    "    znew['HeadingRateHorAbs'] = zdelta['HeadingRateHorAbs_Next']\n",
    "\n",
    "    znew['SpeedVer'] = zcur['SpeedVer'] + dt * (tfac * zcur['AccnVer'] + (1-tfac) * znew['AccnVer'])\n",
    "    znew['SpeedHor'] = zcur['SpeedHor'] + dt * (tfac * zcur['AccnHor'] + (1-tfac) * znew['AccnHor'])\n",
    "    znew['Heading'] = zcur['Heading'] + dt * (tfac * zcur['HeadingRateHorAbs'] + (1-tfac) * znew['HeadingRateHorAbs'])\n",
    "    znew['Heading'] = normalize_angle(znew['Heading'])\n",
    "    \n",
    "    znew['TimeElapsed'] = zcur['TimeElapsed'] + dt\n",
    "    znew['X'] = zcur['X'] + dt * abs(zcur['SpeedHor'])*np.cos(zcur['Heading']) + np.random.normal(*Xdrift)\n",
    "    znew['Y'] = zcur['Y'] + dt * abs(zcur['SpeedHor'])*np.sin(zcur['Heading']) + np.random.normal(*Ydrift)\n",
    "    znew['AltitudeAGL'] = zcur['AltitudeAGL'] + dt * zcur['SpeedVer']\n",
    "    znew['Heading'] = normalize_angle(znew['Heading'])\n",
    "    #znew['AltitudeAGL'] = zcur['AltitudeAGL'] + dt * (tfac* zcur['Vspeed'] + (1-tfac)*znew['Vspeed'])\n",
    "    return znew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fb9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_track(zcur, sim_duration_mins, dt = 1., iseed=0, tfac=0.5, Xdrift = (0.,4.), Ydrift = (0.,4.)):\n",
    "    np.random.seed(iseed)\n",
    "    ydelta = {ix: 0. for ix in Y_varnames}\n",
    "    znew = deepcopy(zcur)\n",
    "    sim = [deepcopy(znew)]\n",
    "    for i in range(int(sim_duration_mins*60/dt)):\n",
    "        xtmp = np.atleast_2d([zcur[ix] for ix in X_varnames])\n",
    "        x_to_use = X_scaler_func.transform(X_poly_func.transform(xtmp))\n",
    "        for k, yvar in enumerate(Y_varnames): \n",
    "            #ynew, ystd = models.loc[(fit_type, yvar), cur_mode].predict(x_to_use, return_std=True)\n",
    "            this_model = models[(2,'L')] if zcur['AltitudeAGL'] < 400. else models[(2,'H')]\n",
    "            ynew = this_model.predict(x_to_use)\n",
    "            ydelta[yvar] = Y_scaler_func.inverse_transform(np.atleast_2d(ynew))[0,0]\n",
    "#             res_var = yvar +'_res'\n",
    "#             res_new = models.loc[(fit_type, res_var), cur_mode].predict(x_to_use)\n",
    "#             res_delta = Y_scalers[(cur_mode, res_var)].inverse_transform(np.atleast_2d(res_new))[0,0]\n",
    "            ydelta[yvar] = ydelta[yvar] + np.random.normal(0,0.01)\n",
    "        znew = forward_move(zcur, ydelta, dt, tfac, Xdrift, Ydrift)\n",
    "        for j, ilag in enumerate(list_of_time_lags): \n",
    "            if i > ilag-2:\n",
    "                for ivar in cols_to_lag:\n",
    "                    znew[f'{ivar}_{int(ilag)}ago'] = sim[-ilag][ivar]\n",
    "        #print(znew.keys())\n",
    "        if (znew['AltitudeAGL'] < -100) | (znew['AltitudeAGL'] > 5000) | (znew['SpeedHor'] < -5.):\n",
    "            break\n",
    "        sim.append(deepcopy(znew))\n",
    "        zcur = deepcopy(znew)\n",
    "    simdf = pd.DataFrame(sim)\n",
    "    return simdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c709e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zcur = {ix: 0. for ix in X_varnames + ['TimeElapsed']}\n",
    "zcur['X'] = 0.#bounds[0] + 30*1000\n",
    "zcur['Y'] = 0.#bounds[1] + 30*1000.\n",
    "zcur['Heading'] = 1.\n",
    "zcur['HeadingRate'] = 0.05\n",
    "zcur['AltitudeAGL'] = 100.\n",
    "zcur['SpeedVer'] = 0.\n",
    "zcur['SpeedHor'] = 1.\n",
    "zcur['AccnVer'] = 0.01\n",
    "zcur['AccnHor'] = 0.01\n",
    "print(zcur)\n",
    "isimdf = simulate_track(zcur, sim_duration_mins=10, tfac=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7,1, figsize=(10,10), sharex=True)\n",
    "axs = axs.flatten()\n",
    "vars_to_plot = [ix for ix in X_varnames if 'ago' not in ix] + ['AccnVer']\n",
    "for i, iname in enumerate(vars_to_plot):\n",
    "    axs[i].plot(isimdf['TimeElapsed'], isimdf[iname], '-b')\n",
    "    axs[i].set_ylabel(iname)\n",
    "axs[-1].plot(isimdf['TimeElapsed'], isimdf['Heading'],'.b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a477ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507be805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20960a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3d6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3aeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca98dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heading rate chnage to heading rate times the sign of heading rate from previus point\n",
    "# to the response variables\n",
    "# and to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_of_calibration(yvar, imode):\n",
    "    results = {ix: models.xs(ix).loc[yvar, imode].coef_ for ix in ['ARD']}\n",
    "    df = pd.DataFrame({key:np.around(val,10) for key, val in results.items()})\n",
    "    df[df.abs() < 1e-5] = np.nan\n",
    "    df['var_id'] = X_poly.get_feature_names_out() + ' '\n",
    "    new_dict1 = {f'x{ix} ':iy for ix, iy in enumerate(list(covariates))}\n",
    "    new_dict2 = {f' x{ix} ':iy for ix, iy in enumerate(list(covariates))}\n",
    "    df['var_name'] = df['var_id']\n",
    "    for iid, iname in zip(new_dict1.keys(), covariates):\n",
    "        df['var_name'] = df['var_name'].str.replace(iid,f'{iname} ' )\n",
    "    for iid, iname in zip(new_dict2.keys(), covariates):\n",
    "        df['var_name'] = df['var_name'].str.replace(iid,iname )\n",
    "    df.set_index('var_name', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e8c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac37e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models = {}\n",
    "Y_scalers = {}\n",
    "for imode in mode_list:\n",
    "    Xmat = cdfs[imode].loc[:, covariates].values\n",
    "    X_to_fit = X_scalers[imode].fit_transform(X_poly.fit_transform(Xmat))\n",
    "    imodels = {}\n",
    "    print(f'Fitting model for mode {imode}..')\n",
    "    for yvar in predictables:\n",
    "        Yvec = cdfs[imode].loc[:, yvar].values\n",
    "        Y_scalers[(imode, yvar)] = StandardScaler()#QuantileTransformer(output_distribution='normal')\n",
    "        Y_to_fit = Y_scalers[(imode, yvar)].fit_transform(Yvec.reshape(-1,1)).reshape(-1)\n",
    "        imodels[('OLR', yvar)] = LinearRegression(fit_intercept=False, n_jobs=4, copy_X=True).fit(X_to_fit, Y_to_fit)\n",
    "        imodels[('LASSO', yvar)] = LassoCV(fit_intercept=False, cv=10, selection='random', n_alphas=100, eps=1e-2, \n",
    "                                    tol=1e-3, n_jobs=4, verbose=False, max_iter=20000).fit(X_to_fit, Y_to_fit)\n",
    "#         imodels[('BRR', yvar)] = BayesianRidge(fit_intercept=False, compute_score=True, tol=1e-10, \n",
    "#                                         verbose=False, alpha_init=1., lambda_init=1).fit(X_to_fit, Y_to_fit)\n",
    "        imodels[('ARD', yvar)] = ARDRegression(compute_score=True, fit_intercept=False, n_iter=400, tol=1e-2, \n",
    "                                        verbose=False).fit(X_to_fit, Y_to_fit)\n",
    "        for itype in ['OLR','LASSO', 'ARD']:\n",
    "            X_to_fit = X_scalers[imode].fit_transform(X_poly.fit_transform(Xmat))\n",
    "            Ypred_sc = imodels[(itype, yvar)].predict(X_to_fit)\n",
    "            Ypred = Y_scalers[(imode, yvar)].inverse_transform(np.atleast_2d(Ypred_sc).T)[:,0]\n",
    "            cdfs[imode][yvar+'_mean_'+itype] = Ypred\n",
    "            rvar = yvar + '_res'\n",
    "            Yres = Yvec - Ypred\n",
    "            #Yres = np.power(np.abs(Yvec - Ypred),2)\n",
    "            cdfs[imode][rvar] = Yres\n",
    "            Y_scalers[(imode, rvar)] = StandardScaler()#QuantileTransformer(output_distribution='normal')\n",
    "            Yres_to_fit = Y_scalers[(imode, rvar)].fit_transform(Yres.reshape(-1,1)).reshape(-1)\n",
    "            imodels[(itype, rvar)] = LinearRegression(fit_intercept=False, n_jobs=4).fit(X_to_fit, Yres_to_fit)\n",
    "            Rpred_sc = imodels[(itype, rvar)].predict(X_to_fit)\n",
    "            Rpred = Y_scalers[(imode, rvar)].inverse_transform(np.atleast_2d(Rpred_sc).T)[:,0]\n",
    "            cdfs[imode][rvar+'_pred'] = Rpred\n",
    "            #print(yvar, itype, ': ', np.around(cdfs[imode][yvar+'_res'].pow(2).mean()**0.5,4), end=\", \")\n",
    "        #print('\\n')\n",
    "    models[imode] = imodels\n",
    "models = pd.DataFrame(models)\n",
    "models.index.set_names(['RegType', 'OutVar'], inplace=True)\n",
    "models.sort_index(level=0, inplace=True)\n",
    "# access via models.loc[('OLR', 'HaccnDiff'), 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94b4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b608ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OrographicUpdraft_100m_0Deg'].hist(bins=50, range=(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibool = df['TrackID'].isin(df['TrackID'].sample(100).values)\n",
    "idata = df.loc[ibool,'HeadingRate'].values.squeeze()\n",
    "fig, ax = plt.subplots(figsize = (10,3))\n",
    "cm = tsaplots.plot_acf(idata, lags = 100, ax= ax, title = 'ACF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce547ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf6213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27562891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SurfaceRoughness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39682f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SurfaceRoughness.hist(bins=50, range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142c554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d72277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ef3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = pd.DataFrame({'a':[1,3,3,6,10,11], 'b':[0,0,0,1,1,1]})\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f464ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy.groupby('b')['a'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = 14\n",
    "vdftrack = vdf[vdf['TrackID']==14]\n",
    "cdftrack = cdf[cdf['TrackID']==14]\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "cm1 = ax.scatter(vdftrack['X'], vdftrack['Y'], c=vdftrack['AltitudeAGL'], s=1, cmap='viridis')\n",
    "# cbar, _ = create_gis_axis_new(fig, ax, cm1, km_bar=0.1)\n",
    "# cbar.set_label('Altitude AGL (m)')\n",
    "# #ax.scatter(tdf.X, tdf.Y, marker='1', color='k', s=100, alpha=1, linewidth=2)\n",
    "# #_, _ = create_gis_axis_new(fig, ax, None, km_bar=km_bar)\n",
    "# #ax.plot(odf.X, odf.Y, '.k', markersize=1, alpha=0.99, label='Telemetry data')\n",
    "# put_start_end_text(ax, simdf, lag=1, fsize=8)\n",
    "# #ax.set_xlim(extent[:2])\n",
    "# #ax.set_ylim(extent[2:])\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(output_fig_dir,f'sim_track.png'), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5afca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf['SpeedHor'].hist(bins=100, range=(0,30), density=True)\n",
    "vdf[vdf['TrackID']>0]['SpeedHor'].hist(bins=100, range=(0,30), density=True)\n",
    "vdf[vdf['TrackID']>0]['SpeedHorUnit'].hist(bins=100, range=(0,30), density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e8c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = cdf[cdf['TrackID'] == 2].iloc[:30]\n",
    "jdf = vdf[vdf['TrackID'] == 2].iloc[:20]\n",
    "plt.plot(idf['X'], idf['Y'])\n",
    "plt.plot(jdf['X'], jdf['Y'])\n",
    "plt.plot(idf['X'].iloc[0], idf['Y'].iloc[0],'*g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf['HeadingHor'], idf['HeadingHor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e49d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf['HeadingHor'].iloc[123400:123410], vdf['HeadingHorUnit'].iloc[123400:123410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf['HeadingHor'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf['HeadingHor'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29cb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee07ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf_track = vdf[vdf['TrackID']==1]\n",
    "cdf_track = resample_telemetry_track(vdf_track)\n",
    "vdf_track2 = vdf[vdf['TrackID']==2]\n",
    "cdf_track2 = resample_telemetry_track(vdf_track2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5df08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.concat([cdf_track, cdf_track2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c58b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.Group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(telemetry_dir, 'df_constant_rate_1s.pkl')\n",
    "sdf = pd.read_pickle(fpath)\n",
    "sort_according_to_columns(sdf, ['Group','AnimalID','TimeLocal'])\n",
    "sdf['Sex'] = sdf['Sex'].str.decode(\"utf-8\")\n",
    "sdf['Age'] = sdf['Age'].str.decode(\"utf-8\")\n",
    "sdf['Group'] = sdf['Group'].str.decode(\"utf-8\")\n",
    "print_memory_usage(sdf, by='Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssrs.raster import transform_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5641b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSG_CRS = 'ESRI:102008'\n",
    "GEO_CRS = 'EPSG:4326'\n",
    "xlocs, ylocs = transform_coordinates(CSG_CRS, GEO_CRS,  sdf['X'].values, sdf['Y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d036ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d408c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf['SpeedHor'] = np.sqrt(sdf['SpeedX']**2 + sdf['SpeedY']**2)\n",
    "sdf['Heading'] = np.degrees(np.arctan2(sdf['SpeedX'], sdf['SpeedY']))\n",
    "sdf['Xahead_50m_0Deg'] = sdf['X'] + 50.*np.sin(np.radians(sdf['Heading']))\n",
    "sdf['Yahead_50m_0Deg'] = sdf['Y'] + 50.*np.cos(np.radians(sdf['Heading']))\n",
    "sdf['Xahead_50m_45DegRight'] = sdf['X'] + 50.*np.sin(np.radians(sdf['Heading'] + 10.))\n",
    "sdf['Yahead_50m_45DegRight'] = sdf['Y'] + 50.*np.cos(np.radians(sdf['Heading'] + 10.))\n",
    "sdf['Xahead_50m_45DegLeft'] = sdf['X'] + 50.*np.sin(np.radians(sdf['Heading'] - 10.))\n",
    "sdf['Yahead_50m_45DegLeft'] = sdf['Y'] + 50.*np.cos(np.radians(sdf['Heading'] - 10.))\n",
    "sdf['Xahead_50m_10DegRight'] = sdf['X'] + 50.*np.sin(np.radians(sdf['Heading'] + 10.))\n",
    "sdf['Yahead_50m_10DegRight'] = sdf['Y'] + 50.*np.cos(np.radians(sdf['Heading'] + 10.))\n",
    "sdf['Xahead_50m_10DegLeft'] = sdf['X'] + 50.*np.sin(np.radians(sdf['Heading'] - 10.))\n",
    "sdf['Yahead_50m_10DegLeft'] = sdf['Y'] + 50.*np.cos(np.radians(sdf['Heading'] - 10.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff047df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.Heading.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd00fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a79be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.loc[sdf['TrackPointCount'] < 6*60, 'TrackID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcecf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Group']=='wy'].AnimalID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd85191",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = 18\n",
    "idf = sdf[sdf['TrackID'] == track_id]\n",
    "fdf = df[df['TrackID'] == track_id]\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(idf['X'], idf['Y'], '-r', label=\"Track\")\n",
    "ax.plot(fdf['X'], fdf['Y'], '*k', label=\"Track\", markersize=2)\n",
    "# ax.plot(idf['Xahead_50m_0Deg'], idf['Yahead_50m_0Deg'], '-b', label=\"50 m in direction\")\n",
    "# ax.plot(idf['Xahead_50m_45DegRight'], idf['Yahead_50m_45DegRight'], '-g', label=\"50 m, 45 deg to the right\")\n",
    "# ax.plot(idf['Xahead_50m_45DegLeft'], idf['Yahead_50m_45DegLeft'], '-k', label=\"50 m, 45 deg to the left\")\n",
    "# ax.plot(idf['Xahead_50m_45DegRight'], idf['Yahead_50m_45DegRight'], '-g', label=\"50 m, 45 deg to the right\")\n",
    "# ax.plot(idf['Xahead_50m_45DegLeft'], idf['Yahead_50m_45DegLeft'], '-k', label=\"50 m, 45 deg to the left\")\n",
    "# #ax.plot(idf['Xahead_50m_0deg'], idf['Yahead_50m_0deg'], '-r', label=\"50 m in direction\")\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daacc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf['X'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdec2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lis of covariates\n",
    "# look ahead points at\n",
    "# - 50 m in direction\n",
    "# - 50 m 45 deg either side\n",
    "# - 50 m or 100m , 45 deg or 10 deg\n",
    "# - groundelevation, slope and aspect - 3dep 10m\n",
    "# - wind speed at 80 m\n",
    "# - updrafts, deardoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "relevant_cols = ['Group', 'X', 'Y', 'Altitude', 'TrackTimeElapsed', 'TrackID', \n",
    "                'VDOP','HDOP', 'TimeUTC', 'TimeLocal', 'Age', 'AnimalID', 'Sex']\n",
    "\n",
    "list_of_sdfs = []\n",
    "for track_id in [1,2,3]:\n",
    "    idftrack = df.loc[df['TrackID']==track_id, relevant_cols]\n",
    "    sdf =  resample_telemetry_track(\n",
    "        idftrack, \n",
    "        dt = 1.,\n",
    "        dim_colnames = ['Altitude', 'X', 'Y'],\n",
    "        dop_colnames = ['VDOP', 'HDOP', 'HDOP'],\n",
    "        dop_factors = [4.5, 2.5*np.sqrt(2), 2.5*np.sqrt(2)],\n",
    "        dim_model_errors = [0.02, 0.5, 0.5],\n",
    "        drop_variances = True,\n",
    "        drop_metrics = True\n",
    "    )\n",
    "    list_of_sdfs.append(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.concat(list_of_sdfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idf in list_of_sdfs:\n",
    "    print(idf.shape)\n",
    "sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_track_dfs = [df[df['TrackID'] == ix] for ix in df.TrackID.unique() if ix > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TrackID.nunique(), len(list_of_track_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d11342",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf['SpeedHor'] = np.sqrt(sdf['SpeedX']**2 + sdf['SpeedY']**2)\n",
    "sdf['Heading'] = np.arctan2(sdf['SpeedX'], sdf['SpeedY']))\n",
    "sdf['Xahead_50m_0deg'] = sdf['X'] + 50.*np.sin(sdf['Heading'])\n",
    "sdf['Yahead_50m_0deg'] = sdf['Y'] + 50.*np.cos(sdf['Heading'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_hrrr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_OF_HRRR_VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c095c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf =  resample_telemetry_track(\n",
    "    idftrack, \n",
    "    dt = 1.,\n",
    "    dim_colnames = ['Altitude', 'X', 'Y'],\n",
    "    dop_colnames = ['VDOP', 'HDOP', 'HDOP'],\n",
    "    dop_factors = [4.5, 2.5*np.sqrt(2), 2.5*np.sqrt(2)],\n",
    "    dim_model_errors = [0.02, 0.25, 0.25],\n",
    "    drop_variances = True,\n",
    "    drop_metrics = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "ax.plot(idftrack['TrackTimeElapsed'], idftrack['X'])\n",
    "ax.plot(sdf['TrackTimeElapsed'], sdf['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(list_of_times,list_of_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "tobs = df_obs['TrackTimeElapsed'].values\n",
    "    list_of_obs = list(df_obs[var_name].values)\n",
    "\n",
    "newdf['TimeUTC'] = pd.date_range(\n",
    "        start=df_obs['TimeUTC'].iloc[0], periods=len(newdf), freq=str(delta_t) + \"S\")\n",
    "    newdf['TimeLocal'] = pd.date_range(\n",
    "        start=df_obs['TimeLocal'].iloc[0], periods=len(newdf), freq=str(delta_t) + \"S\")\n",
    "    newdf['TrackID'] = track_id\n",
    "    if plot == True:\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(12, 4))\n",
    "        ax[0].plot(tobs, df_obs[var_name], '+r',\n",
    "                   label='Telemetry', markersize=2.)\n",
    "        for i, iname in enumerate(motion_model.labels):\n",
    "            ax[i].plot(newdf['TimeElapsed'], newdf[iname],\n",
    "                       '-b', label='Resampled')\n",
    "        ax[0].legend()\n",
    "    newdf = ikf.df_smoother[ikf.labels + ['TimeElapsed']]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ede484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resampled_track(idftrack):\n",
    "    assert len(idf['TrackID'].unique()) == 1, 'Track id has to be unique'\n",
    "    idf1 = kalman_smoother_ca1d(idftrack, var_name = 'Altitude', dop_name = 'VDOP', plot=False)\n",
    "    idf2 = kalman_smoother_ca1d(idftrack, var_name = 'X', dop_name = 'HDOP', plot=False)\n",
    "    idf3 = kalman_smoother_ca1d(idftrack, var_name = 'Y', dop_name = 'HDOP', plot=False)\n",
    "    idf = pd.concat([idf1, idf2, idf3], axis=1, join='outer')\n",
    "    idf = idf.loc[:,~idf.columns.duplicated()].copy()\n",
    "    idf.rename(columns = {\n",
    "        'Altitude_speed': 'Vspeed', 'Altitude_accn':'Vaccn',\n",
    "        'X_speed': 'HspeedX', 'Y_speed':'HspeedY',\n",
    "        'X_accn': 'HaccnX', 'Y_accn':'HaccnY',\n",
    "        'TimeElapsed':'TrackTimeElapsed'\n",
    "    }, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017fb456",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = df['wy']\n",
    "varnames = ['X', 'Y', 'Altitude', 'TrackTimeElapsed', 'TrackID', 'VDOP','HDOP', 'TimeUTC', 'TimeLocal']\n",
    "track_id = 14\n",
    "idftrack = idf.loc[idf['TrackID']==14, varnames]\n",
    "idf1 = kalman_smoother_ca1d(idftrack, var_name = 'Altitude', dop_name = 'VDOP', plot=True)\n",
    "idf2 = kalman_smoother_ca1d(idftrack, var_name = 'X', dop_name = 'HDOP', plot=True)\n",
    "idf3 = kalman_smoother_ca1d(idftrack, var_name = 'Y', dop_name = 'HDOP', plot=True)\n",
    "idf = pd.concat([idf1, idf2, idf3], axis=1, join='outer')\n",
    "idf = idf.loc[:,~idf.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501209eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.rename(columns = {\n",
    "    'Altitude_speed': 'Vspeed', 'Altitude_accn':'Vaccn',\n",
    "    'X_speed': 'HspeedX', 'Y_speed':'HspeedY',\n",
    "    'X_accn': 'HaccnX', 'Y_accn':'HaccnY',\n",
    "    'TimeElapsed':'TrackTimeElapsed'\n",
    "}, inplace = True, errors='ignore')\n",
    "idf.sort_index(axis=1, inplace=True)\n",
    "idftrack.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ba6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "idftrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89458950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     istr = 'Agl'\n",
    "#     for idist in ival:\n",
    "#         dist_change = df['VelocityVer']*idist/df['VelocityHor']\n",
    "#         in_col = f'GroundElevationD{str(idist)}'\n",
    "#         out_col = f'{istr}D{str(idist)}'\n",
    "#         df[out_col] = df['Altitude'] - df[in_col] + 1.*dist_change\n",
    "#     in_cols = [f'{istr}D{str(ix)}' for ix in ival]\n",
    "#     out_col = f'{istr}{ikey}'\n",
    "#     print(out_col, in_cols)\n",
    "#     df[out_col] = agl_fn(df[in_cols].values, axis=1)\n",
    "#     df[f'{out_col}Diff'] = df[out_col] - df[istr]\n",
    "#     df.drop(columns=in_cols, inplace=True)\n",
    "#df.drop(columns=[ix for ix in df.columns if 'ElevationD' in ix], inplace=True)\n",
    "%%time\n",
    "\n",
    "for iflag in ['L30', 'R30']:\n",
    "    istr = 'OroSmooth'\n",
    "    in_cols = [f'{istr}D{str(ix)}{iflag}' for ix in dist_dict['Near']]\n",
    "    out_col = f'{istr}Near{iflag}'\n",
    "    print(out_col, in_cols)\n",
    "    df[out_col] = oro_fn(df[in_cols].values, axis=1)\n",
    "    df[f'{out_col}Diff'] = df[out_col] - df[f'{istr}Near']\n",
    "    \n",
    "df.drop(columns=[ix for ix in df.columns if 'SmoothD' in ix], inplace=True)\n",
    "df.sort_index(inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oro_fn = np.mean\n",
    "elev_fn = np.mean\n",
    "agl_fn = np.mean\n",
    "dist_dict = {\n",
    "    'Near': [25,50,75], 'Mid': [400,500,600], \n",
    "    'Far': [900,1000,1100], #'Farther':[1800,2000,2200]\n",
    "}\n",
    "for ikey, ival in dist_dict.items():\n",
    "    for istr, ifn in zip(['OroSmooth','Elev'], [oro_fn, elev_fn]):\n",
    "        in_cols = [f'{istr}D{str(ix)}' for ix in ival]\n",
    "        out_col = f'{istr}{ikey}'\n",
    "        print(out_col, in_cols)\n",
    "        df[out_col] = ifn(df[in_cols].values, axis=1)\n",
    "        df[f'{out_col}Diff'] = df[out_col] - df[istr]\n",
    "        df.drop(columns=in_cols, inplace=True)\n",
    "        if ikey == 'Near':\n",
    "            for iflag in ['L30', 'R30']:\n",
    "                in_cols = [f'{istr}D{str(ix)}{iflag}' for ix in ival]\n",
    "                out_col = f'{istr}{ikey}{iflag}'\n",
    "                print(out_col, in_cols)\n",
    "                df[out_col] = ifn(df[in_cols].values, axis=1)\n",
    "                df[f'{out_col}Diff'] = df[out_col] - df[f'{istr}{ikey}']\n",
    "                df.drop(columns=in_cols, inplace=True)\n",
    "df.drop(columns=[ix for ix in df.columns if 'ElevD' in ix], inplace=True)\n",
    "df.drop(columns=[ix for ix in df.columns if 'OroSmoothD' in ix], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs_env",
   "language": "python",
   "name": "rs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
